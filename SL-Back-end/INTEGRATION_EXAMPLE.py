"""
ë°±í…ŒìŠ¤íŠ¸ ìµœì í™” í†µí•© ì˜ˆì œ
====================================

ì´ íŒŒì¼ì€ ë‘ ê°€ì§€ ì£¼ìš” ìµœì í™”ë¥¼ ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ ì„œë¹„ìŠ¤ì— í†µí•©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

1. ì¬ë¬´ ë°ì´í„° ì¥ê¸° ìºì‹± (financial_cache.py)
2. ì¡°ê±´ì‹ ì‚¬ì „ ë¶„ì„ ë° ì„ íƒì  íŒ©í„° ê³„ì‚° (factor_dependency_analyzer.py)
"""

from datetime import date, timedelta
from typing import List, Dict, Optional, Any
from sqlalchemy.ext.asyncio import AsyncSession
import polars as pl
import logging

from app.services.financial_cache import financial_cache
from app.services.factor_dependency_analyzer import factor_analyzer
from app.services.backtest_extreme_optimized import ExtremeOptimizer
from app.schemas.backtest import BacktestCreateRequest, BacktestResult

logger = logging.getLogger(__name__)


async def run_optimized_backtest_example(
    db: AsyncSession,
    request: BacktestCreateRequest,
    stock_universe: List[str]
) -> BacktestResult:
    """
    ìµœì í™”ê°€ ì ìš©ëœ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜ˆì œ

    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        request: ë°±í…ŒìŠ¤íŠ¸ ìš”ì²­ (ì¡°ê±´ í¬í•¨)
        stock_universe: ì¢…ëª© ìœ ë‹ˆë²„ìŠ¤

    Returns:
        BacktestResult
    """

    start_date = request.start_date
    end_date = request.end_date

    logger.info(f"ğŸš€ ìµœì í™” ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘: {start_date} ~ {end_date}")
    logger.info(f"ì¢…ëª© ìˆ˜: {len(stock_universe)}")

    # ========================================================================
    # OPTIMIZATION 1: ì¬ë¬´ ë°ì´í„° ì¥ê¸° ìºì‹±
    # ========================================================================

    logger.info("=" * 80)
    logger.info("ìµœì í™” 1: ì¬ë¬´ ë°ì´í„° Redis ìºì‹± (3ê°œì›” TTL)")
    logger.info("=" * 80)

    # í•„ìš”í•œ ì—°ë„ ë²”ìœ„ ê³„ì‚° (1ë…„ ì „ë¶€í„°)
    years_needed = [
        str(start_date.year - 1),
        str(start_date.year),
        str(end_date.year)
    ]
    years_needed = sorted(list(set(years_needed)))  # ì¤‘ë³µ ì œê±°

    logger.info(f"ğŸ“… ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì—°ë„: {years_needed}")

    # ìºì‹œë¥¼ í†µí•œ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ (ì²« ì‹¤í–‰ì€ DB ì¡°íšŒ, ì´í›„ëŠ” Redis ìºì‹œ)
    financial_data_by_year = {}

    for year in years_needed:
        logger.info(f"  - {year}ë…„ ë°ì´í„° ì¡°íšŒ ì¤‘...")

        # ì‚¬ì—…ë³´ê³ ì„œ (ì—°ê²° ì¬ë¬´ì œí‘œ)
        annual_data = await financial_cache.get_financial_statements_cached(
            db=db,
            stock_codes=stock_universe,
            fiscal_year=year,
            report_code='11011'  # ì‚¬ì—…ë³´ê³ ì„œ
        )

        financial_data_by_year[year] = annual_data

        logger.info(f"    âœ… {year}ë…„: {len(annual_data)}ê°œ ì¢…ëª©")

    # ì¬ë¬´ ë°ì´í„°ë¥¼ Polars DataFrameìœ¼ë¡œ ë³€í™˜ (backtest_extreme_optimized.py í˜•ì‹)
    financial_records = []

    for year, year_data in financial_data_by_year.items():
        for stock_code, statements in year_data.items():
            # ì¬ë¬´ì œí‘œì—ì„œ í•„ìš”í•œ í•­ëª© ì¶”ì¶œ
            bs = statements.get('balance_sheet', {})
            is_data = statements.get('income_statement', {})
            cf = statements.get('cashflow_statement', {})

            record = {
                'stock_code': stock_code,
                'fiscal_year': int(year),
                # ì†ìµê³„ì‚°ì„œ
                'ë§¤ì¶œì•¡': is_data.get('ë§¤ì¶œì•¡', {}).get('thstrm_amount'),
                'ì˜ì—…ì´ìµ': is_data.get('ì˜ì—…ì´ìµ', {}).get('thstrm_amount'),
                'ë‹¹ê¸°ìˆœì´ìµ': is_data.get('ë‹¹ê¸°ìˆœì´ìµ', {}).get('thstrm_amount'),
                'ë§¤ì¶œì´ì´ìµ': is_data.get('ë§¤ì¶œì´ì´ìµ', {}).get('thstrm_amount'),
                'ë§¤ì¶œì›ê°€': is_data.get('ë§¤ì¶œì›ê°€', {}).get('thstrm_amount'),
                # ì¬ë¬´ìƒíƒœí‘œ
                'ìì‚°ì´ê³„': bs.get('ìì‚°ì´ê³„', {}).get('thstrm_amount'),
                'ìë³¸ì´ê³„': bs.get('ìë³¸ì´ê³„', {}).get('thstrm_amount'),
                'ë¶€ì±„ì´ê³„': bs.get('ë¶€ì±„ì´ê³„', {}).get('thstrm_amount'),
                'ìœ ë™ìì‚°': bs.get('ìœ ë™ìì‚°', {}).get('thstrm_amount'),
                'ìœ ë™ë¶€ì±„': bs.get('ìœ ë™ë¶€ì±„', {}).get('thstrm_amount'),
                'í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°': bs.get('í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°', {}).get('thstrm_amount'),
                # í˜„ê¸ˆíë¦„í‘œ
                'ì˜ì—…í™œë™í˜„ê¸ˆíë¦„': cf.get('ì˜ì—…í™œë™í˜„ê¸ˆíë¦„', {}).get('thstrm_amount'),
                'íˆ¬ìí™œë™í˜„ê¸ˆíë¦„': cf.get('íˆ¬ìí™œë™í˜„ê¸ˆíë¦„', {}).get('thstrm_amount'),
                'ì¬ë¬´í™œë™í˜„ê¸ˆíë¦„': cf.get('ì¬ë¬´í™œë™í˜„ê¸ˆíë¦„', {}).get('thstrm_amount'),
            }

            financial_records.append(record)

    financial_pl = pl.DataFrame(financial_records)
    logger.info(f"âœ… ì¬ë¬´ ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {len(financial_records)}ê°œ ë ˆì½”ë“œ")

    # ========================================================================
    # OPTIMIZATION 2: ì¡°ê±´ì‹ ì‚¬ì „ ë¶„ì„ ë° ì„ íƒì  íŒ©í„° ê³„ì‚°
    # ========================================================================

    logger.info("=" * 80)
    logger.info("ìµœì í™” 2: ì¡°ê±´ì‹ ë¶„ì„ ë° ì„ íƒì  íŒ©í„° ê³„ì‚°")
    logger.info("=" * 80)

    # ì‚¬ìš©ìì˜ ë§¤ìˆ˜ ì¡°ê±´ ì¶”ì¶œ
    buy_conditions = request.buy_conditions if request.buy_conditions else []
    buy_expression = request.buy_expression

    logger.info(f"ğŸ“‹ ë§¤ìˆ˜ ì¡°ê±´ ìˆ˜: {len(buy_conditions)}")

    # ì¡°ê±´ì‹ì—ì„œ í•„ìš”í•œ íŒ©í„° ì¶”ì¶œ
    required_factors = factor_analyzer.extract_factors_from_conditions(
        conditions=buy_conditions,
        buy_expression=buy_expression
    )

    logger.info(f"ğŸ” í•„ìš” íŒ©í„°: {sorted(required_factors) if required_factors else 'ëª¨ë“  íŒ©í„°'}")

    # íŒ©í„° ê³„ì‚° ë§ˆìŠ¤í¬ ìƒì„±
    compute_mask = factor_analyzer.get_factor_compute_mask(required_factors)

    # ë³µì¡ë„ ë¶„ì„
    complexity = factor_analyzer.analyze_condition_complexity(
        conditions=buy_conditions,
        buy_expression=buy_expression
    )

    logger.info(f"ğŸ“Š íŒ©í„° ì‚¬ìš©: {complexity['factor_count']}/{complexity['total_factors']}ê°œ")
    logger.info(f"âš¡ ì˜ˆìƒ ì†ë„ í–¥ìƒ: {complexity['estimated_speedup']:.1f}x")

    if complexity['optimization_enabled']:
        logger.info("âœ… ì„ íƒì  íŒ©í„° ê³„ì‚° ìµœì í™” í™œì„±í™”")
    else:
        logger.info("â„¹ï¸ ëª¨ë“  íŒ©í„° ê³„ì‚° (ìµœì í™” ë¯¸ì ìš©)")

    # ========================================================================
    # íŒ©í„° ê³„ì‚° (ìµœì í™” ì ìš©)
    # ========================================================================

    logger.info("=" * 80)
    logger.info("íŒ©í„° ê³„ì‚° ì‹œì‘ (ìµœì í™” ì ìš©)")
    logger.info("=" * 80)

    # ì—¬ê¸°ì„œëŠ” price_plê³¼ stock_prices_plì„ ì´ë¯¸ ë¡œë“œí–ˆë‹¤ê³  ê°€ì •
    # ì‹¤ì œë¡œëŠ” DBì—ì„œ ê°€ê²© ë°ì´í„°ë¥¼ ì¡°íšŒí•´ì•¼ í•¨
    # (ì´ ì˜ˆì œì—ì„œëŠ” ìƒëµ)

    # ê±°ë˜ì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    trading_dates = []  # ì‹¤ì œë¡œëŠ” ì˜ì—…ì¼ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±
    current = start_date
    while current <= end_date:
        trading_dates.append(current)
        current += timedelta(days=1)

    logger.info(f"ğŸ“… ê±°ë˜ì¼ ìˆ˜: {len(trading_dates)}")

    # ExtremeOptimizer ì´ˆê¸°í™”
    optimizer = ExtremeOptimizer()

    # ğŸš€ ìµœì í™”ëœ íŒ©í„° ê³„ì‚° ì‹¤í–‰
    # compute_maskë¥¼ ì „ë‹¬í•˜ì—¬ í•„ìš”í•œ íŒ©í„°ë§Œ ê³„ì‚°
    """
    factor_results = optimizer.calculate_all_indicators_batch_extreme(
        price_pl=price_pl,  # OHLCV ë°ì´í„° (Polars DataFrame)
        financial_pl=financial_pl,  # ì¬ë¬´ ë°ì´í„° (ìœ„ì—ì„œ ìºì‹œë¡œ ë¡œë“œ)
        calc_dates=trading_dates,
        stock_prices_pl=stock_prices_pl,  # ì‹œê°€ì´ì•¡ ë°ì´í„°
        compute_mask=compute_mask  # âš¡ ìµœì í™”: í•„ìš”í•œ íŒ©í„°ë§Œ ê³„ì‚°
    )

    logger.info(f"âœ… íŒ©í„° ê³„ì‚° ì™„ë£Œ: {len(factor_results)}ê°œ ë‚ ì§œ")
    """

    # ========================================================================
    # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì´í›„ ë¡œì§)
    # ========================================================================

    # ì´ ì‹œì ì—ì„œ factor_resultsë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ìˆ˜/ë§¤ë„ ë¡œì§ ì‹¤í–‰
    # í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜, ì„±ê³¼ ê³„ì‚° ë“±

    logger.info("=" * 80)
    logger.info("âœ… ìµœì í™” ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info("=" * 80)

    # BacktestResult ë°˜í™˜ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ìƒì„¸ ê²°ê³¼ í¬í•¨)
    # return backtest_result


async def demonstrate_cache_warming():
    """
    ìºì‹œ ì›Œë°ì—… ì˜ˆì œ
    ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìºì‹±í•˜ì—¬ ì²« ì‹¤í–‰ ì‹œ ì„±ëŠ¥ í–¥ìƒ
    """
    logger.info("ğŸ”¥ ìºì‹œ ì›Œë°ì—… ì‹œì‘")

    from app.core.database import get_db

    async for db in get_db():
        # ì£¼ìš” ì¢…ëª©ë“¤ì˜ ìµœê·¼ 3ë…„ ì¬ë¬´ ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ
        major_stocks = ['005930', '000660', '035420', '051910', '035720']  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤ ë“±

        current_year = 2024
        years = [str(current_year - i) for i in range(3)]

        for year in years:
            await financial_cache.get_financial_statements_cached(
                db=db,
                stock_codes=major_stocks,
                fiscal_year=year,
                report_code='11011'
            )
            logger.info(f"  âœ… {year}ë…„ ë°ì´í„° ìºì‹± ì™„ë£Œ")

        logger.info("ğŸ”¥ ìºì‹œ ì›Œë°ì—… ì™„ë£Œ")
        break


async def demonstrate_cache_invalidation():
    """
    ìºì‹œ ë¬´íš¨í™” ì˜ˆì œ
    ì¬ë¬´ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë  ë•Œ ì‚¬ìš©
    """
    logger.info("ğŸ—‘ï¸ ìºì‹œ ë¬´íš¨í™” ì˜ˆì œ")

    # íŠ¹ì • ì¢…ëª©ì˜ íŠ¹ì • ì—°ë„ë§Œ ë¬´íš¨í™”
    await financial_cache.invalidate_financial_cache(
        stock_code='005930',
        fiscal_year='2023'
    )
    logger.info("  âœ… ì‚¼ì„±ì „ì 2023ë…„ ìºì‹œ ë¬´íš¨í™”")

    # íŠ¹ì • ì—°ë„ ì „ì²´ ë¬´íš¨í™” (ëª¨ë“  ì¢…ëª©)
    await financial_cache.invalidate_financial_cache(
        fiscal_year='2024'
    )
    logger.info("  âœ… 2024ë…„ ì „ì²´ ìºì‹œ ë¬´íš¨í™”")

    # ì „ì²´ ìºì‹œ ë¬´íš¨í™” (ì£¼ì˜: ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©)
    # await financial_cache.invalidate_financial_cache()
    # logger.info("  âœ… ì „ì²´ ìºì‹œ ë¬´íš¨í™”")


def demonstrate_factor_analysis():
    """
    íŒ©í„° ë¶„ì„ ì˜ˆì œ
    ë‹¤ì–‘í•œ ì¡°ê±´ì‹ì—ì„œ íŒ©í„° ì¶”ì¶œ ì‹œì—°
    """
    logger.info("ğŸ” íŒ©í„° ë¶„ì„ ì˜ˆì œ")

    # ì˜ˆì œ 1: ë‹¨ìˆœ ì¡°ê±´
    simple_conditions = [
        {'factor': 'PER', 'operator': '<', 'value': 10},
        {'factor': 'PBR', 'operator': '<', 'value': 1},
    ]

    factors1 = factor_analyzer.extract_factors_from_conditions(
        conditions=simple_conditions
    )
    logger.info(f"  ì˜ˆì œ 1 (ë‹¨ìˆœ): {factors1}")

    # ì˜ˆì œ 2: ë…¼ë¦¬ì‹ ì¡°ê±´
    complex_expression = {
        'expression': '(PER < 10 and PBR < 1) or (ROE > 15 and DEBT_RATIO < 50)',
        'conditions': [
            {'id': 'A', 'factor': 'PER', 'operator': '<', 'value': 10},
            {'id': 'B', 'factor': 'PBR', 'operator': '<', 'value': 1},
            {'id': 'C', 'factor': 'ROE', 'operator': '>', 'value': 15},
            {'id': 'D', 'factor': 'DEBT_RATIO', 'operator': '<', 'value': 50},
        ]
    }

    factors2 = factor_analyzer.extract_factors_from_conditions(
        buy_expression=complex_expression
    )
    logger.info(f"  ì˜ˆì œ 2 (ë³µì¡): {factors2}")

    # ë³µì¡ë„ ë¶„ì„
    analysis = factor_analyzer.analyze_condition_complexity(
        buy_expression=complex_expression
    )
    logger.info(f"  ë³µì¡ë„ ë¶„ì„: {analysis}")


if __name__ == "__main__":
    """
    ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì—¬ ì˜ˆì œë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ì‹¤í–‰ ë°©ë²•:
    python INTEGRATION_EXAMPLE.py
    """
    import asyncio

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # íŒ©í„° ë¶„ì„ ì˜ˆì œ (ë™ê¸° í•¨ìˆ˜)
    demonstrate_factor_analysis()

    # ë¹„ë™ê¸° ì˜ˆì œë“¤
    # asyncio.run(demonstrate_cache_warming())
    # asyncio.run(demonstrate_cache_invalidation())
