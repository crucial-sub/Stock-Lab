"""
ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
- ë¹„ë™ê¸° SQLAlchemy (asyncpg)
- ì»¤ë„¥ì…˜ í’€ë§
- ì¿¼ë¦¬ ìµœì í™”
"""
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from sqlalchemy.orm import declarative_base
from sqlalchemy.pool import NullPool
from sqlalchemy import event, text
from typing import AsyncGenerator
import logging

from app.core.config import get_settings

settings = get_settings()
logger = logging.getLogger(__name__)

# ë¹„ë™ê¸° ì—”ì§„ ìƒì„± (í”„ë¡œë•ì…˜ í™˜ê²½ ìµœì í™” - Connection Pooling)
engine = create_async_engine(
    settings.DATABASE_URL,
    echo=settings.DATABASE_ECHO if hasattr(settings, 'DATABASE_ECHO') else False,
    # âœ… ì»¤ë„¥ì…˜ í’€ í™œì„±í™” (ì™„ì „ ë¹„ë™ê¸° ì „í™˜ìœ¼ë¡œ í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
    # advanced_backtest.pyì˜ ë™ê¸°/ë¹„ë™ê¸° í˜¼ìš© ì œê±° ì™„ë£Œ
    pool_size=10,  # ê¸°ë³¸ ì»¤ë„¥ì…˜ 10ê°œ
    max_overflow=20,  # ìµœëŒ€ 30ê°œê¹Œì§€ í™•ì¥ ê°€ëŠ¥
    pool_timeout=30,  # ì»¤ë„¥ì…˜ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    pool_recycle=3600,  # 1ì‹œê°„ë§ˆë‹¤ ì»¤ë„¥ì…˜ ì¬ìƒì„±
    pool_pre_ping=True,  # ì»¤ë„¥ì…˜ ìœ íš¨ì„± ê²€ì¦
    # ëŒ€ìš©ëŸ‰ ì¿¼ë¦¬ ìµœì í™”
    connect_args={
        "statement_cache_size": 0,  # prepared statement ìºì‹œ ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
        "server_settings": {
            "jit": "off",  # JIT ì»´íŒŒì¼ ë¹„í™œì„±í™” (ì§§ì€ ì¿¼ë¦¬ ìµœì í™”)
            "application_name": "quant_api",
        }
    },
)

# ì„¸ì…˜ íŒ©í† ë¦¬
AsyncSessionLocal = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,  # ì»¤ë°‹ í›„ ê°ì²´ ë§Œë£Œ ë°©ì§€
    autoflush=False,  # ìë™ í”ŒëŸ¬ì‹œ ë¹„í™œì„±í™” (ì„±ëŠ¥ í–¥ìƒ)
    autocommit=False,
)

# Base ëª¨ë¸
Base = declarative_base()


# ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ì˜ì¡´ì„±
async def get_db() -> AsyncGenerator[AsyncSession, None]:
    """
    FastAPI ì˜ì¡´ì„±ìœ¼ë¡œ ì‚¬ìš©í•  DB ì„¸ì…˜ ìƒì„±ê¸°

    Usage:
        @app.get("/items")
        async def get_items(db: AsyncSession = Depends(get_db)):
            ...
    """
    from fastapi import HTTPException

    async with AsyncSessionLocal() as session:
        try:
            yield session
        except HTTPException:
            # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „ë‹¬ (429, 404 ë“±)
            raise
        except Exception as e:
            await session.rollback()
            logger.error(f"Database session error: {e}")
            raise
        finally:
            await session.close()


# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
async def init_db():
    """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± (ê°œë°œìš©)"""
    async with engine.begin() as conn:
        # await conn.run_sync(Base.metadata.drop_all)  # ì£¼ì˜: ëª¨ë“  í…Œì´ë¸” ì‚­ì œ
        await conn.run_sync(Base.metadata.create_all)
    logger.info("Database initialized successfully")


# ë°ì´í„°ë² ì´ìŠ¤ ì¢…ë£Œ
async def close_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
    await engine.dispose()
    logger.info("Database connections closed")


# PostgreSQL ì„±ëŠ¥ ìµœì í™” ì„¤ì •
@event.listens_for(engine.sync_engine, "connect")
def set_postgresql_pragma(dbapi_conn, connection_record):
    """
    PostgreSQL ì—°ê²° ì‹œ ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì ìš©
    - work_mem: ì •ë ¬/í•´ì‹œ ì‘ì—… ë©”ëª¨ë¦¬ ì¦ê°€ (ëŒ€ìš©ëŸ‰ ì¿¼ë¦¬ìš©)
    - effective_cache_size: ìºì‹œ í¬ê¸° ì„¤ì •
    """
    cursor = dbapi_conn.cursor()
    cursor.execute("SET work_mem = '256MB'")  # ì •ë ¬/ì¡°ì¸ ë©”ëª¨ë¦¬ ì¦ê°€
    cursor.execute("SET effective_cache_size = '4GB'")  # ì¿¼ë¦¬ í”Œë˜ë„ˆ ìµœì í™”
    cursor.execute("SET random_page_cost = 1.1")  # SSD ìµœì í™”
    cursor.close()


# ğŸš€ ìµœì í™”: SQL ì¿¼ë¦¬ ë¡œê·¸ ë¹„í™œì„±í™” (ì„±ëŠ¥ í–¥ìƒ)
# ì¿¼ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (ê°œë°œ í™˜ê²½)
# @event.listens_for(engine.sync_engine, "before_cursor_execute")
# def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):
#     """ì¿¼ë¦¬ ì‹¤í–‰ ì „ ë¡œê¹…"""
#     if settings.DEBUG:
#         logger.debug(f"SQL Query: {statement}")


# ëŒ€ìš©ëŸ‰ ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬ í—¬í¼
class BulkInsertHelper:
    """
    ëŒ€ìš©ëŸ‰ ë°ì´í„° ë°°ì¹˜ ì‚½ì… í—¬í¼

    Example:
        async with BulkInsertHelper(session, chunk_size=10000) as bulk:
            await bulk.insert(StockPrice, price_data_list)
    """

    def __init__(self, session: AsyncSession, chunk_size: int = 10000):
        self.session = session
        self.chunk_size = chunk_size

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if exc_type is None:
            await self.session.commit()
        else:
            await self.session.rollback()

    async def insert(self, model_class, data_list: list):
        """ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²­í¬ ë‹¨ìœ„ë¡œ ì‚½ì…"""
        total = len(data_list)
        for i in range(0, total, self.chunk_size):
            chunk = data_list[i:i + self.chunk_size]
            self.session.add_all([model_class(**data) for data in chunk])
            await self.session.flush()
            logger.info(f"Inserted {min(i + self.chunk_size, total)}/{total} records")

        await self.session.commit()
        logger.info(f"Bulk insert completed: {total} records")


# ì½ê¸° ì „ìš© ì„¸ì…˜ (ë¶„ì„/ë°±í…ŒìŠ¤íŒ…ìš© - íŠ¸ëœì­ì…˜ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”)
async def get_readonly_db() -> AsyncGenerator[AsyncSession, None]:
    """
    ì½ê¸° ì „ìš© ì„¸ì…˜ (ë°±í…ŒìŠ¤íŒ…, íŒ©í„° ê³„ì‚°ìš©)
    - autocommit=Trueë¡œ íŠ¸ëœì­ì…˜ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”
    """
    async with AsyncSessionLocal() as session:
        try:
            # ì½ê¸° ì „ìš© ëª¨ë“œ ì„¤ì •
            await session.execute(text("SET TRANSACTION READ ONLY"))
            yield session
        finally:
            await session.close()