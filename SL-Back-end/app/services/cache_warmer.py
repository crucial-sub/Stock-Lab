"""
ë°±í…ŒìŠ¤íŠ¸ ìºì‹œ Pre-warming ì„œë¹„ìŠ¤
ë§¤ì¼ ìƒˆë²½ì— ì¸ê¸° ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ì„ ë¯¸ë¦¬ ì‹¤í–‰í•˜ì—¬ ìºì‹±
"""
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, date, timedelta
from decimal import Decimal
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc, and_

from app.core.cache import get_cache
from app.core.database import AsyncSessionLocal
from app.models.backtest import BacktestSession
from app.models.company import Company
from app.models.stock_price import StockPrice
from app.services.factor_calculator_complete import CompleteFactorCalculator

logger = logging.getLogger(__name__)


# ì¸ê¸° ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ (ì‹¤ì œ ì‚¬ìš©ì ë¡œê·¸ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸ í•„ìš”)
POPULAR_BACKTEST_CONDITIONS = [
    # ì €PER ê³ ROE ì „ëµ (ê°€ì¹˜ì£¼ íˆ¬ì)
    {
        "name": "ì €PER_ê³ ROE",
        "factors": ["PER", "ROE"],
        "period_days": 365,
        "top_n": 20,
        "description": "PER ë‚®ê³  ROE ë†’ì€ ê°€ì¹˜ì£¼"
    },
    # ê³ ë°°ë‹¹ ì €PBR ì „ëµ
    {
        "name": "ê³ ë°°ë‹¹_ì €PBR",
        "factors": ["ë°°ë‹¹ìˆ˜ìµë¥ ", "PBR"],
        "period_days": 365,
        "top_n": 30,
        "description": "ë°°ë‹¹ ë†’ê³  PBR ë‚®ì€ ì•ˆì •ì£¼"
    },
    # ëª¨ë©˜í…€ ì „ëµ
    {
        "name": "ê³ ROE_ê³ ì˜ì—…ì´ìµë¥ ",
        "factors": ["ROE", "ì˜ì—…ì´ìµë¥ "],
        "period_days": 180,
        "top_n": 20,
        "description": "ìˆ˜ìµì„± ë†’ì€ ì„±ì¥ì£¼"
    },
    # í€„ë¦¬í‹° ì „ëµ
    {
        "name": "ì €ë¶€ì±„ë¹„ìœ¨_ê³ ìê¸°ìë³¸ë¹„ìœ¨",
        "factors": ["ë¶€ì±„ë¹„ìœ¨", "ìê¸°ìë³¸ë¹„ìœ¨"],
        "period_days": 365,
        "top_n": 25,
        "description": "ì¬ë¬´ ê±´ì „ì„± ìš°ìˆ˜ ê¸°ì—…"
    },
]


async def get_popular_conditions_from_db() -> List[Dict[str, Any]]:
    """
    ì‹¤ì œ ì‚¬ìš©ìê°€ ìì£¼ ì‚¬ìš©í•œ ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ ë¶„ì„
    ìµœê·¼ 30ì¼ê°„ ì‹¤í–‰ íšŸìˆ˜ ìƒìœ„ 50ê°œ ì¶”ì¶œ
    """
    try:
        async with AsyncSessionLocal() as db:
            # ìµœê·¼ 30ì¼ê°„ ì‹¤í–‰ëœ ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ ë¶„ì„
            thirty_days_ago = datetime.now() - timedelta(days=30)

            # BacktestSessionì—ì„œ ìì£¼ ì‚¬ìš©ëœ ì¡°í•© ë¶„ì„
            query = select(BacktestSession).where(
                BacktestSession.created_at >= thirty_days_ago
            ).order_by(desc(BacktestSession.created_at)).limit(100)

            result = await db.execute(query)
            sessions = result.scalars().all()

            # ì¡°ê±´ ë¹ˆë„ ë¶„ì„ (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
            # ì§€ê¸ˆì€ ê¸°ë³¸ ì¡°ê±´ ë°˜í™˜
            return POPULAR_BACKTEST_CONDITIONS

    except Exception as e:
        logger.error(f"Failed to get popular conditions: {e}")
        return POPULAR_BACKTEST_CONDITIONS


async def get_all_active_stocks(db: AsyncSession) -> List[str]:
    """
    ëª¨ë“  í™œì„± ì¢…ëª© ì½”ë“œ ì¡°íšŒ
    """
    try:
        # ìµœê·¼ ê±°ë˜ê°€ ìˆëŠ” ì¢…ëª©ë§Œ ì¡°íšŒ
        latest_date_query = select(func.max(StockPrice.trade_date))
        latest_date_result = await db.execute(latest_date_query)
        latest_date = latest_date_result.scalar()

        if not latest_date:
            logger.warning("No stock price data found")
            return []

        # ìµœê·¼ 30ì¼ ì´ë‚´ ê±°ë˜ê°€ ìˆëŠ” ì¢…ëª©
        cutoff_date = latest_date - timedelta(days=30)

        # Company í…Œì´ë¸”ê³¼ ì¡°ì¸í•˜ì—¬ stock_code ê°€ì ¸ì˜¤ê¸°
        query = select(Company.stock_code).join(
            StockPrice, Company.company_id == StockPrice.company_id
        ).where(
            StockPrice.trade_date >= cutoff_date
        ).distinct()

        result = await db.execute(query)
        stock_codes = [row[0] for row in result.fetchall()]

        logger.info(f"Found {len(stock_codes)} active stocks")
        return stock_codes

    except Exception as e:
        logger.error(f"Failed to get active stocks: {e}")
        return []


async def warm_price_data():
    """
    ê°€ê²© ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìºì‹± (ë°±í…ŒìŠ¤íŠ¸ í•µì‹¬ ë°ì´í„°)
    - ìµœê·¼ 3ë…„ì¹˜ ì „ì²´ ì¢…ëª© ê°€ê²© ë°ì´í„° (ì˜êµ¬ ìºì‹±)
    - ë°±í…ŒìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë°ì´í„°
    """
    logger.info("ğŸ”¥ Starting price data warming (3 years, permanent cache)...")
    cache = get_cache()

    async with AsyncSessionLocal() as db:
        try:
            # ìµœì‹  ë‚ ì§œ ì¡°íšŒ
            latest_date_query = select(func.max(StockPrice.trade_date))
            latest_date_result = await db.execute(latest_date_query)
            latest_date = latest_date_result.scalar()

            if not latest_date:
                logger.warning("No stock price data found")
                return

            # ìµœê·¼ 3ë…„ì¹˜ ë°ì´í„° (ë°±í…ŒìŠ¤íŠ¸ ìµœëŒ€ ì»¤ë²„ë¦¬ì§€)
            three_years_ago = latest_date - timedelta(days=1095)  # 365 * 3

            logger.info(f"Warming price data from {three_years_ago} to {latest_date}")

            # ì „ì²´ ì¢…ëª© ê°€ê²© ë°ì´í„° ì¡°íšŒ (í•„í„° ì—†ìŒ, Company ì •ë³´ í¬í•¨)
            from app.models.company import Company

            query = select(
                StockPrice.company_id,
                Company.stock_code,
                Company.company_name,
                Company.industry,
                Company.market_type,
                StockPrice.trade_date,
                StockPrice.open_price,
                StockPrice.high_price,
                StockPrice.low_price,
                StockPrice.close_price,
                StockPrice.volume,
                StockPrice.trading_value,
                StockPrice.market_cap,
                StockPrice.listed_shares
            ).join(
                Company, StockPrice.company_id == Company.company_id
            ).where(
                and_(
                    StockPrice.trade_date >= three_years_ago,
                    StockPrice.trade_date <= latest_date,
                    StockPrice.close_price.isnot(None),
                    StockPrice.volume > 0
                )
            ).order_by(
                StockPrice.trade_date,
                Company.stock_code
            )

            result = await db.execute(query)
            all_prices = result.mappings().all()

            if all_prices:
                # ì „ì²´ ê°€ê²© ë°ì´í„°ë¥¼ ìºì‹± (í•„í„° ì—†ëŠ” ë² ì´ìŠ¤ ë°ì´í„°)
                price_data = [
                    {
                        "company_id": str(p["company_id"]),
                        "stock_code": p["stock_code"],
                        "stock_name": p["company_name"],
                        "industry": p["industry"],
                        "market_type": p["market_type"],
                        "date": p["trade_date"].isoformat(),
                        "trade_date": p["trade_date"].isoformat(),  # í˜¸í™˜ì„±
                        "open_price": float(p["open_price"]) if p["open_price"] else None,
                        "high_price": float(p["high_price"]) if p["high_price"] else None,
                        "low_price": float(p["low_price"]) if p["low_price"] else None,
                        "close_price": float(p["close_price"]),
                        "volume": int(p["volume"]),
                        "trading_value": float(p["trading_value"]) if p["trading_value"] else None,
                        "market_cap": float(p["market_cap"]) if p["market_cap"] else None,
                        "listed_shares": int(p["listed_shares"]) if p["listed_shares"] else None,
                    }
                    for p in all_prices
                ]

                # ë‚ ì§œ ë²”ìœ„ë³„ë¡œ ìºì‹± (ì ˆëŒ€ ë‚ ì§œ ê¸°ì¤€ í‘œì¤€ ê¸°ê°„)
                # ë°±í…ŒìŠ¤íŠ¸ì™€ í˜¸í™˜ë˜ë„ë¡ ê³ ì •ëœ í‘œì¤€ ê¸°ê°„ ì‚¬ìš©
                from datetime import date

                standard_periods = [
                    (date(2024, 1, 1), date(2024, 12, 31), "2024_full"),     # 2024ë…„ ì „ì²´
                    (date(2023, 1, 1), date(2024, 12, 31), "2023-2024"),     # 2ë…„
                    (date(2022, 1, 1), date(2024, 12, 31), "2022-2024"),     # 3ë…„
                    (date(2024, 7, 1), date(2024, 12, 31), "2024_h2"),       # 2024 í•˜ë°˜ê¸°
                ]

                for start_date, end_date, label in standard_periods:
                    filtered_data = [
                        p for p in price_data
                        if start_date <= datetime.fromisoformat(p["trade_date"]).date() <= end_date
                    ]

                    cache_key = f"price_data:all:{start_date}:{end_date}"
                    await cache.set(cache_key, filtered_data, ttl=0)  # ì˜êµ¬ ìºì‹± (TTL=0)
                    logger.info(f"âœ… Cached {label} price data: {len(filtered_data)} records (permanent)")

            logger.info("âœ… Price data warming completed!")

        except Exception as e:
            logger.error(f"âŒ Price data warming failed: {e}")


async def warm_factor_calculations():
    """
    íŒ©í„° ê³„ì‚° ê²°ê³¼ë¥¼ ë¯¸ë¦¬ ìºì‹±
    - ëª¨ë“  ì¢…ëª©ì˜ ìµœì‹  íŒ©í„° ê°’
    - ì£¼ìš” íŒ©í„°ë§Œ ìºì‹± (ë©”ëª¨ë¦¬ íš¨ìœ¨)
    """
    logger.info("ğŸ”¥ Starting factor calculation warming...")
    cache = get_cache()

    async with AsyncSessionLocal() as db:
        try:
            # ì£¼ìš” íŒ©í„° ë¦¬ìŠ¤íŠ¸ (ìì£¼ ì‚¬ìš©ë˜ëŠ” ê²ƒë§Œ)
            important_factors = [
                "PER", "PBR", "ROE", "ROA", "EPS",
                "ë°°ë‹¹ìˆ˜ìµë¥ ", "ì˜ì—…ì´ìµë¥ ", "ìˆœì´ìµë¥ ",
                "ë¶€ì±„ë¹„ìœ¨", "ìê¸°ìë³¸ë¹„ìœ¨", "ìœ ë™ë¹„ìœ¨"
            ]

            # ìµœì‹  ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
            latest_date_query = select(func.max(StockPrice.trade_date))
            latest_date_result = await db.execute(latest_date_query)
            base_date = latest_date_result.scalar()

            if not base_date:
                logger.warning("No stock price data found")
                return

            logger.info(f"Using base date: {base_date}")

            # í™œì„± ì¢…ëª© ì½”ë“œ ì¡°íšŒ
            stock_codes = await get_all_active_stocks(db)
            if not stock_codes:
                logger.warning("No active stocks found")
                return

            # íŒ©í„° ê³„ì‚°ê¸° ì´ˆê¸°í™”
            calculator = CompleteFactorCalculator(db)

            # âš¡ ì „ì²´ ì¢…ëª©ì„ í•œ ë²ˆì— ê³„ì‚° (ë°°ì¹˜ í¬ê¸° ì¦ê°€)
            batch_size = 1000  # 100 -> 500ìœ¼ë¡œ ì¦ê°€
            for i in range(0, len(stock_codes), batch_size):
                batch = stock_codes[i:i + batch_size]

                try:
                    # ëª¨ë“  íŒ©í„° ê³„ì‚°
                    factors_df = await calculator.calculate_all_factors(
                        stock_codes=batch,
                        date=datetime.combine(base_date, datetime.min.time()) if isinstance(base_date, date) else base_date
                    )

                    if factors_df is not None and not factors_df.empty:
                        # íŒ©í„°ë³„ë¡œ ìºì‹±
                        for factor_name in important_factors:
                            if factor_name in factors_df.columns:
                                cache_key = f"quant:factor:{factor_name}:{base_date}:batch_{i}"
                                factor_data = factors_df[[factor_name]].to_dict()
                                await cache.set(cache_key, factor_data, ttl=0)  # ì˜êµ¬ ìºì‹± (TTL=0)

                        logger.info(f"âœ… Cached factors for batch {i//batch_size + 1} ({len(batch)} stocks, permanent)")

                except Exception as e:
                    logger.error(f"âŒ Failed to calculate factors for batch {i}: {e}")
                    continue

            logger.info("âœ… Factor warming completed!")

        except Exception as e:
            logger.error(f"âŒ Factor warming failed: {e}")


async def warm_stock_rankings():
    """
    ì¢…ëª© ë­í‚¹ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìºì‹±
    - ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª©
    - ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª©
    - ê° íŒ©í„°ë³„ ìƒìœ„ ì¢…ëª©
    """
    logger.info("ğŸ”¥ Starting stock ranking warming...")
    cache = get_cache()

    async with AsyncSessionLocal() as db:
        try:
            # ìµœì‹  ë‚ ì§œ
            latest_date_query = select(func.max(StockPrice.trade_date))
            latest_date_result = await db.execute(latest_date_query)
            latest_date = latest_date_result.scalar()

            if not latest_date:
                return

            # ì‹œê°€ì´ì•¡ ìƒìœ„ 100ê°œ (StockPriceì—ì„œ ìµœì‹  ë°ì´í„° ì‚¬ìš©)
            market_cap_query = select(
                Company.stock_code,
                Company.company_name,
                StockPrice.market_cap
            ).join(
                StockPrice, Company.company_id == StockPrice.company_id
            ).where(
                and_(
                    StockPrice.trade_date == latest_date,
                    StockPrice.market_cap.isnot(None)
                )
            ).order_by(desc(StockPrice.market_cap)).limit(100)

            result = await db.execute(market_cap_query)
            top_market_cap = [
                {
                    "stock_code": row[0],
                    "company_name": row[1],
                    "market_cap": float(row[2]) if row[2] else None
                }
                for row in result.fetchall()
            ]

            cache_key = f"quant:ranking:market_cap:top100:{latest_date}"
            await cache.set(cache_key, top_market_cap, ttl=0)  # ì˜êµ¬ ìºì‹± (TTL=0)
            logger.info(f"ğŸ“ˆ Cached market cap top 100 (permanent)")

            # ê±°ë˜ëŸ‰ ìƒìœ„ 100ê°œ (ìµœê·¼ 20ì¼ í‰ê· )
            twenty_days_ago = latest_date - timedelta(days=20)

            volume_query = select(
                Company.stock_code,
                func.avg(StockPrice.volume).label('avg_volume')
            ).join(
                StockPrice, Company.company_id == StockPrice.company_id
            ).where(
                and_(
                    StockPrice.trade_date >= twenty_days_ago,
                    StockPrice.trade_date <= latest_date,
                    StockPrice.volume > 0
                )
            ).group_by(Company.stock_code).order_by(
                desc('avg_volume')
            ).limit(100)

            result = await db.execute(volume_query)
            top_volume = [
                {
                    "stock_code": row[0],
                    "avg_volume": float(row[1]) if row[1] else None
                }
                for row in result.fetchall()
            ]

            cache_key = f"quant:ranking:volume:top100:{latest_date}"
            await cache.set(cache_key, top_volume, ttl=0)  # ì˜êµ¬ ìºì‹± (TTL=0)
            logger.info(f"ğŸ“ˆ Cached volume top 100 (permanent)")

            logger.info("âœ… Ranking warming completed!")

        except Exception as e:
            logger.error(f"âŒ Ranking warming failed: {e}")


async def warm_backtest_results():
    """
    ì¸ê¸° ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë¯¸ë¦¬ ìºì‹±
    (ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ì€ ë§¤ìš° ë¬´ê±°ìš°ë¯€ë¡œ ì„ ë³„ì ìœ¼ë¡œ)
    """
    logger.info("ğŸ”¥ Starting backtest warming...")
    cache = get_cache()

    try:
        # ì¸ê¸° ì¡°ê±´ ê°€ì ¸ì˜¤ê¸°
        conditions = await get_popular_conditions_from_db()

        # ë°±í…ŒìŠ¤íŠ¸ëŠ” ë§¤ìš° ë¬´ê±°ìš°ë¯€ë¡œ ìƒìœ„ 5ê°œë§Œ ì‹¤í–‰
        top_conditions = conditions[:5]

        for condition in top_conditions:
            try:
                cache_key = f"quant:backtest_meta:{condition['name']}"

                # ì´ë¯¸ ìºì‹œì— ìˆìœ¼ë©´ ìŠ¤í‚µ
                if await cache.exists(cache_key):
                    logger.debug(f"âœ“ {condition['name']} already cached")
                    continue

                # ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëŒ€ì‹  ë©”íƒ€ë°ì´í„°ë§Œ ìºì‹±
                # (ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ëŠ” ì‚¬ìš©ì ìš”ì²­ ì‹œ ì‹¤í–‰)
                metadata = {
                    "condition": condition,
                    "warmed_at": datetime.now().isoformat(),
                    "ready": True
                }

                await cache.set(cache_key, metadata, ttl=86400)  # 1ì¼
                logger.info(f"ğŸ’° Warmed backtest metadata: {condition['name']}")

            except Exception as e:
                logger.error(f"âŒ Failed to warm {condition['name']}: {e}")
                continue

        logger.info("âœ… Backtest warming completed!")

    except Exception as e:
        logger.error(f"âŒ Backtest warming failed: {e}")


async def warm_famous_strategies():
    """
    ìœ ëª… íˆ¬ì ì „ëµ 10ê°œ ìºì‹± (ë³‘ë ¬ ì²˜ë¦¬)
    - ê¸‰ë“±ì£¼, ì•ˆì •ì„±ì¥, í”¼í„°ë¦°ì¹˜, ì›Œë Œë²„í• ë“±
    - 30-35ë¶„ ì†Œìš” (4ê°œì”© ë³‘ë ¬ ì²˜ë¦¬)
    """
    logger.info("ğŸ”¥ Starting famous strategies warming (10 strategies, parallel)...")

    try:
        import subprocess
        import os

        # ìœ ëª… ì „ëµ ìºì‹œ ì›Œë° ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        script_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "scripts",
            "warm_all_famous_strategies.py"
        )

        if not os.path.exists(script_path):
            logger.warning(f"âš ï¸ Famous strategies script not found: {script_path}")
            logger.info(f"   Expected path: {script_path}")
            return

        logger.info(f"ğŸ“‚ Running script: {script_path}")

        # ì„œë¸Œí”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰
        result = subprocess.run(
            ["python3", script_path],
            capture_output=True,
            text=True,
            timeout=3600  # 1ì‹œê°„ íƒ€ì„ì•„ì›ƒ
        )

        if result.returncode == 0:
            logger.info("âœ… Famous strategies warming completed!")
            # ì£¼ìš” ë¡œê·¸ë§Œ ì¶œë ¥
            for line in result.stdout.split('\n'):
                if any(keyword in line for keyword in ['âœ…', 'ğŸ”„', 'ë°°ì¹˜', 'ì™„ë£Œ', 'ì‹œì‘']):
                    logger.info(f"   {line}")
        else:
            logger.error(f"âŒ Famous strategies warming failed!")
            logger.error(f"   Return code: {result.returncode}")
            logger.error(f"   Stderr: {result.stderr[:500]}")  # ì²˜ìŒ 500ìë§Œ

    except subprocess.TimeoutExpired:
        logger.error("âŒ Famous strategies warming timeout (1 hour)")
    except Exception as e:
        logger.error(f"âŒ Famous strategies warming failed: {e}")


async def run_cache_warming():
    """
    ì „ì²´ ìºì‹œ ì›Œë° í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
    ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ í†µí•´ ë§¤ì¼ ìƒˆë²½ 3ì‹œì— ì‹¤í–‰ë¨
    """
    start_time = datetime.now()
    logger.info("=" * 80)
    logger.info("ğŸ”¥ğŸ”¥ğŸ”¥ CACHE WARMING STARTED ğŸ”¥ğŸ”¥ğŸ”¥")
    logger.info(f"Start time: {start_time}")
    logger.info("=" * 80)

    try:
        # 0ë‹¨ê³„: ê°€ê²© ë°ì´í„° ìºì‹± (ìµœìš°ì„ !) - ë°±í…ŒìŠ¤íŠ¸ í•µì‹¬ ë°ì´í„°
        await warm_price_data()

        # 1ë‹¨ê³„: íŒ©í„° ê³„ì‚° ìºì‹± (ê¸°ë³¸ ë°ì´í„°) - ê°€ì¥ ì¤‘ìš”!
        await warm_factor_calculations()

        # 2ë‹¨ê³„: ì¢…ëª© ë­í‚¹ ìºì‹±
        await warm_stock_rankings()

        # 3ë‹¨ê³„: ì¸ê¸° ë°±í…ŒìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° ìºì‹±
        await warm_backtest_results()

        # 4ë‹¨ê³„: ìœ ëª… íˆ¬ì ì „ëµ 10ê°œ ìºì‹± (ë³‘ë ¬ ì²˜ë¦¬) - NEW!
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š Phase 4: Famous Strategies Warming")
        logger.info("=" * 80)
        await warm_famous_strategies()

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        logger.info("=" * 80)
        logger.info("ğŸ‰ğŸ‰ğŸ‰ CACHE WARMING COMPLETED ğŸ‰ğŸ‰ğŸ‰")
        logger.info(f"Duration: {duration:.2f} seconds")
        logger.info(f"End time: {end_time}")
        logger.info("=" * 80)

        # ìºì‹œ í†µê³„ ì¶œë ¥
        cache = get_cache()
        stats = await cache.get_cache_stats()
        logger.info(f"ğŸ“Š Cache Stats after warming:")
        logger.info(f"  - Memory Used: {stats.get('used_memory_human', 'N/A')}")
        logger.info(f"  - Hit Ratio: {stats.get('hit_ratio', 0):.2%}")

    except Exception as e:
        logger.error(f"âŒâŒâŒ CACHE WARMING FAILED: {e}", exc_info=True)
        raise


# ìˆ˜ë™ ì‹¤í–‰ìš© í•¨ìˆ˜
async def manual_warm_cache():
    """ìˆ˜ë™ìœ¼ë¡œ ìºì‹œ ì›Œë° ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)"""
    await run_cache_warming()


if __name__ == "__main__":
    import asyncio
    asyncio.run(manual_warm_cache())
