"""
ë°±í…ŒìŠ¤íŠ¸ ìºì‹œ Pre-warming ì„œë¹„ìŠ¤
ë§¤ì¼ ìƒˆë²½ì— ì¸ê¸° ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ì„ ë¯¸ë¦¬ ì‹¤í–‰í•˜ì—¬ ìºì‹±
"""
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, date, timedelta
from decimal import Decimal
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc, and_

from app.core.cache import get_cache
from app.core.database import AsyncSessionLocal
from app.models.backtest import BacktestSession
from app.models.company import Company
from app.models.stock_price import StockPrice
from app.services.factor_calculator_complete import CompleteFactorCalculator

logger = logging.getLogger(__name__)


# ì¸ê¸° ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ (ì‹¤ì œ ì‚¬ìš©ì ë¡œê·¸ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸ í•„ìš”)
POPULAR_BACKTEST_CONDITIONS = [
    # ì €PER ê³ ROE ì „ëµ (ê°€ì¹˜ì£¼ íˆ¬ì)
    {
        "name": "ì €PER_ê³ ROE",
        "factors": ["PER", "ROE"],
        "period_days": 365,
        "top_n": 20,
        "description": "PER ë‚®ê³  ROE ë†’ì€ ê°€ì¹˜ì£¼"
    },
    # ê³ ë°°ë‹¹ ì €PBR ì „ëµ
    {
        "name": "ê³ ë°°ë‹¹_ì €PBR",
        "factors": ["ë°°ë‹¹ìˆ˜ìµë¥ ", "PBR"],
        "period_days": 365,
        "top_n": 30,
        "description": "ë°°ë‹¹ ë†’ê³  PBR ë‚®ì€ ì•ˆì •ì£¼"
    },
    # ëª¨ë©˜í…€ ì „ëµ
    {
        "name": "ê³ ROE_ê³ ì˜ì—…ì´ìµë¥ ",
        "factors": ["ROE", "ì˜ì—…ì´ìµë¥ "],
        "period_days": 180,
        "top_n": 20,
        "description": "ìˆ˜ìµì„± ë†’ì€ ì„±ì¥ì£¼"
    },
    # í€„ë¦¬í‹° ì „ëµ
    {
        "name": "ì €ë¶€ì±„ë¹„ìœ¨_ê³ ìê¸°ìë³¸ë¹„ìœ¨",
        "factors": ["ë¶€ì±„ë¹„ìœ¨", "ìê¸°ìë³¸ë¹„ìœ¨"],
        "period_days": 365,
        "top_n": 25,
        "description": "ì¬ë¬´ ê±´ì „ì„± ìš°ìˆ˜ ê¸°ì—…"
    },
]


async def get_popular_conditions_from_db() -> List[Dict[str, Any]]:
    """
    ì‹¤ì œ ì‚¬ìš©ìê°€ ìì£¼ ì‚¬ìš©í•œ ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ ë¶„ì„
    ìµœê·¼ 30ì¼ê°„ ì‹¤í–‰ íšŸìˆ˜ ìƒìœ„ 50ê°œ ì¶”ì¶œ
    """
    try:
        async with AsyncSessionLocal() as db:
            # ìµœê·¼ 30ì¼ê°„ ì‹¤í–‰ëœ ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ ë¶„ì„
            thirty_days_ago = datetime.now() - timedelta(days=30)

            # BacktestSessionì—ì„œ ìì£¼ ì‚¬ìš©ëœ ì¡°í•© ë¶„ì„
            query = select(BacktestSession).where(
                BacktestSession.created_at >= thirty_days_ago
            ).order_by(desc(BacktestSession.created_at)).limit(100)

            result = await db.execute(query)
            sessions = result.scalars().all()

            # ì¡°ê±´ ë¹ˆë„ ë¶„ì„ (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
            # ì§€ê¸ˆì€ ê¸°ë³¸ ì¡°ê±´ ë°˜í™˜
            return POPULAR_BACKTEST_CONDITIONS

    except Exception as e:
        logger.error(f"Failed to get popular conditions: {e}")
        return POPULAR_BACKTEST_CONDITIONS


async def get_all_active_stocks(db: AsyncSession) -> List[str]:
    """
    ëª¨ë“  í™œì„± ì¢…ëª© ì½”ë“œ ì¡°íšŒ
    """
    try:
        # ìµœê·¼ ê±°ë˜ê°€ ìˆëŠ” ì¢…ëª©ë§Œ ì¡°íšŒ
        latest_date_query = select(func.max(StockPrice.trade_date))
        latest_date_result = await db.execute(latest_date_query)
        latest_date = latest_date_result.scalar()

        if not latest_date:
            logger.warning("No stock price data found")
            return []

        # ìµœê·¼ 30ì¼ ì´ë‚´ ê±°ë˜ê°€ ìˆëŠ” ì¢…ëª©
        cutoff_date = latest_date - timedelta(days=30)

        # Company í…Œì´ë¸”ê³¼ ì¡°ì¸í•˜ì—¬ stock_code ê°€ì ¸ì˜¤ê¸°
        query = select(Company.stock_code).join(
            StockPrice, Company.company_id == StockPrice.company_id
        ).where(
            StockPrice.trade_date >= cutoff_date
        ).distinct()

        result = await db.execute(query)
        stock_codes = [row[0] for row in result.fetchall()]

        logger.info(f"Found {len(stock_codes)} active stocks")
        return stock_codes

    except Exception as e:
        logger.error(f"Failed to get active stocks: {e}")
        return []


async def warm_factor_calculations():
    """
    íŒ©í„° ê³„ì‚° ê²°ê³¼ë¥¼ ë¯¸ë¦¬ ìºì‹±
    - ëª¨ë“  ì¢…ëª©ì˜ ìµœì‹  íŒ©í„° ê°’
    - ì£¼ìš” íŒ©í„°ë§Œ ìºì‹± (ë©”ëª¨ë¦¬ íš¨ìœ¨)
    """
    logger.info("ğŸ”¥ Starting factor calculation warming...")
    cache = get_cache()

    async with AsyncSessionLocal() as db:
        try:
            # ì£¼ìš” íŒ©í„° ë¦¬ìŠ¤íŠ¸ (ìì£¼ ì‚¬ìš©ë˜ëŠ” ê²ƒë§Œ)
            important_factors = [
                "PER", "PBR", "ROE", "ROA", "EPS",
                "ë°°ë‹¹ìˆ˜ìµë¥ ", "ì˜ì—…ì´ìµë¥ ", "ìˆœì´ìµë¥ ",
                "ë¶€ì±„ë¹„ìœ¨", "ìê¸°ìë³¸ë¹„ìœ¨", "ìœ ë™ë¹„ìœ¨"
            ]

            # ìµœì‹  ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
            latest_date_query = select(func.max(StockPrice.trade_date))
            latest_date_result = await db.execute(latest_date_query)
            base_date = latest_date_result.scalar()

            if not base_date:
                logger.warning("No stock price data found")
                return

            logger.info(f"Using base date: {base_date}")

            # í™œì„± ì¢…ëª© ì½”ë“œ ì¡°íšŒ
            stock_codes = await get_all_active_stocks(db)
            if not stock_codes:
                logger.warning("No active stocks found")
                return

            # íŒ©í„° ê³„ì‚°ê¸° ì´ˆê¸°í™”
            calculator = CompleteFactorCalculator(db)

            # ë°°ì¹˜ë¡œ ì²˜ë¦¬ (í•œ ë²ˆì— 100ê°œì”©)
            batch_size = 100
            for i in range(0, len(stock_codes), batch_size):
                batch = stock_codes[i:i + batch_size]

                try:
                    # ëª¨ë“  íŒ©í„° ê³„ì‚°
                    # base_dateê°€ datetime.date ê°ì²´ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    factors_df = await calculator.calculate_all_factors(
                        stock_codes=batch,
                        date=datetime.combine(base_date, datetime.min.time()) if isinstance(base_date, date) else base_date
                    )

                    if factors_df is not None and not factors_df.empty:
                        # íŒ©í„°ë³„ë¡œ ìºì‹±
                        for factor_name in important_factors:
                            if factor_name in factors_df.columns:
                                cache_key = f"quant:factor:{factor_name}:{base_date}:batch_{i}"
                                factor_data = factors_df[[factor_name]].to_dict()
                                await cache.set(cache_key, factor_data, ttl=86400)  # 1ì¼

                        logger.info(f"âœ… Cached factors for batch {i//batch_size + 1} ({len(batch)} stocks)")

                except Exception as e:
                    logger.error(f"âŒ Failed to calculate factors for batch {i}: {e}")
                    continue

            logger.info("âœ… Factor warming completed!")

        except Exception as e:
            logger.error(f"âŒ Factor warming failed: {e}")


async def warm_stock_rankings():
    """
    ì¢…ëª© ë­í‚¹ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìºì‹±
    - ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª©
    - ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª©
    - ê° íŒ©í„°ë³„ ìƒìœ„ ì¢…ëª©
    """
    logger.info("ğŸ”¥ Starting stock ranking warming...")
    cache = get_cache()

    async with AsyncSessionLocal() as db:
        try:
            # ìµœì‹  ë‚ ì§œ
            latest_date_query = select(func.max(StockPrice.trade_date))
            latest_date_result = await db.execute(latest_date_query)
            latest_date = latest_date_result.scalar()

            if not latest_date:
                return

            # ì‹œê°€ì´ì•¡ ìƒìœ„ 100ê°œ (StockPriceì—ì„œ ìµœì‹  ë°ì´í„° ì‚¬ìš©)
            market_cap_query = select(
                Company.stock_code,
                Company.company_name,
                StockPrice.market_cap
            ).join(
                StockPrice, Company.company_id == StockPrice.company_id
            ).where(
                and_(
                    StockPrice.trade_date == latest_date,
                    StockPrice.market_cap.isnot(None)
                )
            ).order_by(desc(StockPrice.market_cap)).limit(100)

            result = await db.execute(market_cap_query)
            top_market_cap = [
                {
                    "stock_code": row[0],
                    "company_name": row[1],
                    "market_cap": float(row[2]) if row[2] else None
                }
                for row in result.fetchall()
            ]

            cache_key = f"quant:ranking:market_cap:top100:{latest_date}"
            await cache.set(cache_key, top_market_cap, ttl=86400)  # 1ì¼
            logger.info(f"ğŸ“ˆ Cached market cap top 100")

            # ê±°ë˜ëŸ‰ ìƒìœ„ 100ê°œ (ìµœê·¼ 20ì¼ í‰ê· )
            twenty_days_ago = latest_date - timedelta(days=20)

            volume_query = select(
                Company.stock_code,
                func.avg(StockPrice.volume).label('avg_volume')
            ).join(
                StockPrice, Company.company_id == StockPrice.company_id
            ).where(
                and_(
                    StockPrice.trade_date >= twenty_days_ago,
                    StockPrice.trade_date <= latest_date,
                    StockPrice.volume > 0
                )
            ).group_by(Company.stock_code).order_by(
                desc('avg_volume')
            ).limit(100)

            result = await db.execute(volume_query)
            top_volume = [
                {
                    "stock_code": row[0],
                    "avg_volume": float(row[1]) if row[1] else None
                }
                for row in result.fetchall()
            ]

            cache_key = f"quant:ranking:volume:top100:{latest_date}"
            await cache.set(cache_key, top_volume, ttl=86400)  # 1ì¼
            logger.info(f"ğŸ“ˆ Cached volume top 100")

            logger.info("âœ… Ranking warming completed!")

        except Exception as e:
            logger.error(f"âŒ Ranking warming failed: {e}")


async def warm_backtest_results():
    """
    ì¸ê¸° ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë¯¸ë¦¬ ìºì‹±
    (ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ì€ ë§¤ìš° ë¬´ê±°ìš°ë¯€ë¡œ ì„ ë³„ì ìœ¼ë¡œ)
    """
    logger.info("ğŸ”¥ Starting backtest warming...")
    cache = get_cache()

    try:
        # ì¸ê¸° ì¡°ê±´ ê°€ì ¸ì˜¤ê¸°
        conditions = await get_popular_conditions_from_db()

        # ë°±í…ŒìŠ¤íŠ¸ëŠ” ë§¤ìš° ë¬´ê±°ìš°ë¯€ë¡œ ìƒìœ„ 5ê°œë§Œ ì‹¤í–‰
        top_conditions = conditions[:5]

        for condition in top_conditions:
            try:
                cache_key = f"quant:backtest_meta:{condition['name']}"

                # ì´ë¯¸ ìºì‹œì— ìˆìœ¼ë©´ ìŠ¤í‚µ
                if await cache.exists(cache_key):
                    logger.debug(f"âœ“ {condition['name']} already cached")
                    continue

                # ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëŒ€ì‹  ë©”íƒ€ë°ì´í„°ë§Œ ìºì‹±
                # (ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ëŠ” ì‚¬ìš©ì ìš”ì²­ ì‹œ ì‹¤í–‰)
                metadata = {
                    "condition": condition,
                    "warmed_at": datetime.now().isoformat(),
                    "ready": True
                }

                await cache.set(cache_key, metadata, ttl=86400)  # 1ì¼
                logger.info(f"ğŸ’° Warmed backtest metadata: {condition['name']}")

            except Exception as e:
                logger.error(f"âŒ Failed to warm {condition['name']}: {e}")
                continue

        logger.info("âœ… Backtest warming completed!")

    except Exception as e:
        logger.error(f"âŒ Backtest warming failed: {e}")


async def run_cache_warming():
    """
    ì „ì²´ ìºì‹œ ì›Œë° í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
    ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ í†µí•´ ë§¤ì¼ ìƒˆë²½ 3ì‹œì— ì‹¤í–‰ë¨
    """
    start_time = datetime.now()
    logger.info("=" * 80)
    logger.info("ğŸ”¥ğŸ”¥ğŸ”¥ CACHE WARMING STARTED ğŸ”¥ğŸ”¥ğŸ”¥")
    logger.info(f"Start time: {start_time}")
    logger.info("=" * 80)

    try:
        # 1ë‹¨ê³„: íŒ©í„° ê³„ì‚° ìºì‹± (ê¸°ë³¸ ë°ì´í„°) - ê°€ì¥ ì¤‘ìš”!
        await warm_factor_calculations()

        # 2ë‹¨ê³„: ì¢…ëª© ë­í‚¹ ìºì‹±
        await warm_stock_rankings()

        # 3ë‹¨ê³„: ì¸ê¸° ë°±í…ŒìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° ìºì‹±
        await warm_backtest_results()

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        logger.info("=" * 80)
        logger.info("ğŸ‰ğŸ‰ğŸ‰ CACHE WARMING COMPLETED ğŸ‰ğŸ‰ğŸ‰")
        logger.info(f"Duration: {duration:.2f} seconds")
        logger.info(f"End time: {end_time}")
        logger.info("=" * 80)

        # ìºì‹œ í†µê³„ ì¶œë ¥
        cache = get_cache()
        stats = await cache.get_cache_stats()
        logger.info(f"ğŸ“Š Cache Stats after warming:")
        logger.info(f"  - Memory Used: {stats.get('used_memory_human', 'N/A')}")
        logger.info(f"  - Hit Ratio: {stats.get('hit_ratio', 0):.2%}")

    except Exception as e:
        logger.error(f"âŒâŒâŒ CACHE WARMING FAILED: {e}", exc_info=True)
        raise


# ìˆ˜ë™ ì‹¤í–‰ìš© í•¨ìˆ˜
async def manual_warm_cache():
    """ìˆ˜ë™ìœ¼ë¡œ ìºì‹œ ì›Œë° ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)"""
    await run_cache_warming()


if __name__ == "__main__":
    import asyncio
    asyncio.run(manual_warm_cache())
