import os
import re
import asyncio
import types
import sys
import uuid
import json
import traceback
import logging
import hashlib
from typing import Optional, List, Dict, Any
from pathlib import Path
from dotenv import load_dotenv
import yaml
try:
    import redis  # type: ignore
except ImportError:
    redis = None

_pydantic_v1_module = None
try:
    import pydantic as _pydantic
    import pydantic.class_validators as _pydantic_class_validators

    _pydantic_v1_module = types.ModuleType("langchain_core.pydantic_v1")
    for attr in dir(_pydantic):
        if attr.startswith("__"):
            continue
        setattr(_pydantic_v1_module, attr, getattr(_pydantic, attr))
    for attr in dir(_pydantic_class_validators):
        if attr.startswith("__"):
            continue
        if hasattr(_pydantic_v1_module, attr):
            continue
        setattr(_pydantic_v1_module, attr, getattr(_pydantic_class_validators, attr))
    _pydantic_v1_module.__all__ = [name for name in dir(_pydantic_v1_module) if not name.startswith("__")]
    sys.modules.setdefault("langchain_core.pydantic_v1", _pydantic_v1_module)
except ImportError:
    pass

LLM_PROVIDER = os.getenv("LLM_PROVIDER", "bedrock").lower()

# ìì—°ì–´ â†’ ìƒìœ„ íŒ©í„° ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (config/nl_category_mapping.json íŒŒì¼ì—ì„œ ë¡œë“œ)

# LangChain ì˜ì¡´ì„±ì€ ë²„ì „ì— ë”°ë¼ ëª¨ë“ˆ ê²½ë¡œê°€ ë‹¬ë¼ì§€ë¯€ë¡œ ê°œë³„ì ìœ¼ë¡œ ë¡œë“œí•œë‹¤.
ChatBedrock = None
create_tool_calling_agent = None
AgentExecutor = None
ChatPromptTemplate = None
MessagesPlaceholder = None
BaseMessage = None
ConversationBufferWindowMemory = None

try:
    from langchain_aws import ChatBedrock  # type: ignore
except ImportError as e:
    print(f"ê²½ê³ : LangChain AWS(ChatBedrock) ì»´í¬ë„ŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. pip install langchain-aws ì‹¤í–‰ í•„ìš”. ì˜¤ë¥˜: {e}")

try:
    from langchain.agents.tool_calling_agent.base import create_tool_calling_agent  # type: ignore
    from langchain.agents.agent import AgentExecutor  # type: ignore
except ImportError:
    try:
        from langchain.agents.tool_calling_agent import create_tool_calling_agent  # type: ignore
        from langchain.agents.agent import AgentExecutor  # type: ignore
    except ImportError:
        try:
            from langchain.agents import create_tool_calling_agent  # type: ignore
            from langchain.agents import AgentExecutor  # type: ignore
        except ImportError:
            try:
                # LangChain 0.3+ ê³„ì—´ì—ì„  classic ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ì´ë™
                from langchain_classic.agents import create_tool_calling_agent, AgentExecutor  # type: ignore
            except ImportError:
                try:
                    from langchain_core.agents import create_tool_calling_agent  # type: ignore
                    from langchain.agents import AgentExecutor  # type: ignore
                except ImportError as e:
                    print(
                        "ê²½ê³ : LangChain Agent ì»´í¬ë„ŒíŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. "
                        "pip install langchain>=0.1,<0.3 ë˜ëŠ” langchain-classic ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”. "
                        f"ì˜¤ë¥˜: {e}"
                    )
                    create_tool_calling_agent = None
                    AgentExecutor = None

try:
    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # type: ignore
except ImportError as e:
    print(f"ê²½ê³ : LangChain Prompt ì»´í¬ë„ŒíŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
    ChatPromptTemplate = None
    MessagesPlaceholder = None

try:
    from langchain_core.messages import BaseMessage  # type: ignore
except ImportError as e:
    print(f"ê²½ê³ : LangChain Message ì»´í¬ë„ŒíŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
    BaseMessage = None

try:
    from langchain.memory import ChatMessageHistory  # type: ignore
except ImportError:
    try:
        # LangChain 0.3+ëŠ” ë©”ëª¨ë¦¬ APIê°€ classic/community íŒ¨í‚¤ì§€ë¡œ ì´ë™í–ˆë‹¤.
        from langchain_community.chat_message_histories import ChatMessageHistory  # type: ignore
        print('ì •ë³´: ChatMessageHistoryë¥¼ langchain_communityì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.')
    except ImportError as e:
        print(f"ê²½ê³ : ChatMessageHistoryë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. pip install langchain-community ì‹¤í–‰ í•„ìš”. ì˜¤ë¥˜: {e}")
        ChatMessageHistory = None

# Load environment variables
env_path = Path(__file__).parent.parent.parent / ".env"
load_dotenv(env_path)
try:
    from factor_sync import FactorSync
except ImportError:
    print("Warning: FactorSync not imported")
    FactorSync = None

try:
    from retrievers.factory import RetrieverFactory
    from retrievers.base_retriever import BaseRetriever
except ImportError:
    print("Warning: Retriever modules not imported")
    RetrieverFactory = None
    BaseRetriever = None

try:
    from retrievers.news_retriever import NewsRetriever
except ImportError:
    print("Warning: NewsRetriever not imported")
    NewsRetriever = None

try:
    from tools import get_tools
except ImportError:
    print("Warning: Tools not imported")
    get_tools = None


class ChatHandler:
    """Handles conversation flow and orchestrates components."""

    GREETING_KEYWORDS = {"ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”", "hi", "hello", "í•˜ì´", "í—¬ë¡œ"}
    DEFAULT_GREETING_RESPONSE = "ì•ˆë…•í•˜ì„¸ìš”! AI assistent ì…ë‹ˆë‹¤ :) ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"
    DSL_CACHE_VERSION = "v1"

    def __init__(self, config_path: str = "config.yaml"):
        if not logging.getLogger().handlers:
            logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        self.config_path = config_path
        self.llm_client = None
        self.rag_retriever = None
        self.factor_sync = None
        self.news_retriever = None
        self.agent_executors: Dict[str, Any] = {}
        self.system_prompts: Dict[str, str] = {}
        self.conversation_history = {}
        self.cache_client = None
        # ì„¤ë¬¸/ì¶”ì²œ ìƒíƒœ
        self.session_state: Dict[str, Dict[str, Any]] = {}
        self.forbidden_patterns: Dict[str, List[str]] = {}
        self.questions: List[Dict[str, Any]] = []
        self.nl_category_mapping: Dict[str, List[str]] = {}
        # LLM ë©”íƒ€ ë°ì´í„° (ì—ëŸ¬ ë¡œê¹…ìš©)
        self.llm_region: Optional[str] = None
        self.llm_model_id: Optional[str] = None
        self.llm_inference_profile_id: Optional[str] = None
        self.llm_target_id: Optional[str] = None

        self._load_config()
        self._load_forbidden_patterns()
        self.questions = self._load_questions()
        self._load_strategies()
        self._load_nl_category_mapping()
        self._init_cache_client()
        self._init_components()
        self._ensure_news_retriever()

    def _needs_news_keyword(self, message: str) -> Optional[str]:
        """ë‰´ìŠ¤ ì˜ë„ì§€ë§Œ í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš° ê°„ë‹¨ ì•ˆë‚´ ë°˜í™˜."""
        msg = (message or "").strip()
        msg_lower = msg.lower()
        news_terms = ["ë‰´ìŠ¤", "ê¸°ì‚¬", "ë™í–¥", "í—¤ë“œë¼ì¸", "ìµœê·¼"]
        if any(t in msg for t in news_terms):
            cleaned = msg
            for t in news_terms:
                cleaned = cleaned.replace(t, "")
            cleaned = cleaned.strip()
            # í‚¤ì›Œë“œ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ë¶€ì¡±í•œ ê²ƒìœ¼ë¡œ íŒë‹¨
            if len(cleaned) < 2:
                return "ì–´ë–¤ ì¢…ëª©/í…Œë§ˆ ë‰´ìŠ¤ê°€ ê¶ê¸ˆí•œì§€ ì•Œë ¤ì£¼ì„¸ìš”. ì˜ˆ) 'ì‚¼ì„±ì „ì ë‰´ìŠ¤ ì•Œë ¤ì¤˜', 'ë°˜ë„ì²´ í…Œë§ˆ ë‰´ìŠ¤ ìš”ì•½í•´ì¤˜'"
        return None

    def _init_cache_client(self):
        """Redis ìºì‹œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”."""
        redis_url = os.getenv("REDIS_URL")
        if not redis_url or not redis:
            return
        try:
            self.cache_client = redis.from_url(redis_url, decode_responses=True)
            self.logger.info(f"Redis cache enabled ({redis_url})")
        except Exception as e:
            self.logger.warning(f"Redis ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.cache_client = None

    def _load_questions(self):
        """ì„¤ë¬¸ ì§ˆë¬¸ì„ ì™¸ë¶€ íŒŒì¼ì—ì„œ ë¡œë“œí•˜ê³ , ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©."""
        path = Path("/app/config/questionnaire.json")
        if not path.exists():
            path = Path(__file__).parent.parent.parent / "config" / "questionnaire.json"
        if path.exists():
            try:
                data = json.loads(path.read_text(encoding="utf-8"))
                if isinstance(data, list) and data:
                    print(f"Loaded questionnaire ({len(data)} questions)")
                    return data
            except Exception as e:
                print(f"Failed to load questionnaire.json: {e}")

        # fallback ê¸°ë³¸ ì„¤ë¬¸ (5ë¬¸í•­)
        return [
            {
                "question_id": "investment_period",
                "text": "ë³´í†µ ì–¼ë§ˆ ë™ì•ˆ ë³´ìœ í•  ìƒê°ìœ¼ë¡œ íˆ¬ìí•˜ì‹œë‚˜ìš”?",
                "order": 1,
                "options": [
                    {"id": "short_term", "label": "ë‹¨ê¸° íˆ¬ì (ë©°ì¹  ~ ëª‡ ì£¼)", "description": "ì§§ê²Œ ì‚¬ê³  íŒ”ë©´ì„œ ë‹¨ê¸° ìˆ˜ìµì„ ë…¸ë ¤ìš”.", "icon": "âš¡", "tags": ["short_term", "style_momentum"]},
                    {"id": "mid_term", "label": "ì¤‘ê¸° íˆ¬ì (ëª‡ ê°œì›”)", "description": "ëª‡ ë‹¬ ì •ë„ íë¦„ì„ ë³´ë©´ì„œ ê°€ì ¸ê°€ëŠ” í¸ì´ì—ìš”.", "icon": "ğŸ“Š", "tags": ["mid_term"]},
                    {"id": "long_term", "label": "ì¥ê¸° íˆ¬ì (1ë…„ ì´ìƒ)", "description": "ì¢‹ì€ ê¸°ì—…ì„ ê³¨ë¼ ì˜¤ë˜ ë“¤ê³  ê°€ê³  ì‹¶ì–´ìš”.", "icon": "ğŸ†", "tags": ["long_term", "style_value"]},
                ],
            },
            {
                "question_id": "investment_style",
                "text": "ì•„ë˜ ì¤‘ì—ì„œ ê°€ì¥ ë³¸ì¸ ìŠ¤íƒ€ì¼ì— ê°€ê¹Œìš´ ê±¸ ê³¨ë¼ì£¼ì„¸ìš”.",
                "order": 2,
                "options": [
                    {"id": "value", "label": "ê°€ì¹˜ / ì €í‰ê°€ ìœ„ì£¼", "description": "ì‹¸ê²Œ ì‚¬ì„œ ì•ˆì „ë§ˆì§„ì„ í™•ë³´í•˜ëŠ” ê²ƒì´ ì¢‹ì•„ìš”.", "icon": "ğŸ’", "tags": ["style_value"]},
                    {"id": "growth", "label": "ì„±ì¥ / ì‹¤ì  ìœ„ì£¼", "description": "ë§¤ì¶œÂ·ì´ìµì´ ë¹ ë¥´ê²Œ ì»¤ì§€ëŠ” ê¸°ì—…ì´ ì¢‹ì•„ìš”.", "icon": "ğŸ“ˆ", "tags": ["style_growth"]},
                    {"id": "quality", "label": "ìš°ëŸ‰ / ì•ˆì •ì„±", "description": "ì¬ë¬´ê°€ íŠ¼íŠ¼í•˜ê³  ë³€ë™ì„±ì´ ë‚®ì€ ê¸°ì—…ì„ ì„ í˜¸í•´ìš”.", "icon": "ğŸ›¡ï¸", "tags": ["style_quality"]},
                    {"id": "momentum", "label": "ëª¨ë©˜í…€ / ì¶”ì„¸", "description": "ì¶”ì„¸ë¥¼ íƒ€ëŠ” ì¢…ëª©, ë¹ ë¥´ê²Œ ì›€ì§ì´ëŠ” ì¢…ëª©ì„ ì¢‹ì•„í•´ìš”.", "icon": "ğŸš€", "tags": ["style_momentum"]},
                    {"id": "dividend", "label": "ë°°ë‹¹ / í˜„ê¸ˆíë¦„", "description": "ë°°ë‹¹ê¸ˆìœ¼ë¡œ ì•ˆì •ì ì¸ ìˆ˜ìµì„ ì–»ê³  ì‹¶ì–´ìš”.", "icon": "ğŸ’°", "tags": ["style_dividend"]},
                ],
            },
            {
                "question_id": "risk_tolerance",
                "text": "ê°€ê²©ì´ ë‚´ë ¤ê°€ë„ ì–´ëŠ ì •ë„ê¹Œì§€ ë²„í‹¸ ìˆ˜ ìˆë‚˜ìš”?",
                "order": 3,
                "options": [
                    {"id": "low", "label": "10% ì´í•˜ í•˜ë½ê¹Œì§€ë§Œ í—ˆìš©", "description": "ì†ì‹¤ì€ ìµœì†Œí™”í•˜ê³  ì‹¶ì–´ìš”.", "icon": "ğŸ§Š", "tags": ["risk_low"]},
                    {"id": "medium", "label": "20% ë‚´ì™¸ í•˜ë½ê¹Œì§€ í—ˆìš©", "description": "ì¤‘ê°„ ì •ë„ ë¦¬ìŠ¤í¬ëŠ” ê°ë‚´í•  ìˆ˜ ìˆì–´ìš”.", "icon": "ğŸŒŠ", "tags": ["risk_medium"]},
                    {"id": "high", "label": "30% ì´ìƒë„ ê°ë‚´ ê°€ëŠ¥", "description": "ìˆ˜ìµì„ ìœ„í•´ ë³€ë™ì„±ì„ ê°ìˆ˜í•  ìˆ˜ ìˆì–´ìš”.", "icon": "ğŸ”¥", "tags": ["risk_high"]},
                ],
            },
            {
                "question_id": "dividend_preference",
                "text": "ë°°ë‹¹ì„ ì„ í˜¸í•˜ì‹œë‚˜ìš”?",
                "order": 4,
                "options": [
                    {"id": "prefer_dividend", "label": "ë°°ë‹¹ ì¤‘ìš”", "description": "ë°°ë‹¹ì„ ì£¼ëŠ” ì¢…ëª©ì´ ì¢‹ì•„ìš”.", "icon": "ğŸ’µ", "tags": ["prefer_dividend"]},
                    {"id": "no_dividend", "label": "ë°°ë‹¹ ìƒê´€ì—†ìŒ", "description": "ë°°ë‹¹ë³´ë‹¤ëŠ” ì„±ì¥/ê°€ê²© ìƒìŠ¹ì— ê´€ì‹¬ ìˆì–´ìš”.", "icon": "ğŸŒ±", "tags": ["no_dividend"]},
                ],
            },
            {
                "question_id": "sector_preference",
                "text": "ì„ í˜¸í•˜ëŠ” ì„¹í„°ê°€ ìˆë‚˜ìš”?",
                "order": 5,
                "options": [
                    {"id": "tech", "label": "ê¸°ìˆ /ì„±ì¥ ì„¹í„°", "description": "AI, ë°˜ë„ì²´, í´ë¼ìš°ë“œ ë“±", "icon": "ğŸ¤–", "tags": ["sector_innovation", "sector_tech"]},
                    {"id": "bluechip", "label": "ì „í†µ ìš°ëŸ‰ ì„¹í„°", "description": "ì€í–‰, í†µì‹ , í•„ìˆ˜ì†Œë¹„ì¬ ë“±", "icon": "ğŸ›ï¸", "tags": ["sector_bluechip"]},
                    {"id": "healthcare", "label": "í—¬ìŠ¤ì¼€ì–´/ë°”ì´ì˜¤", "description": "ì œì•½, ë°”ì´ì˜¤, ì˜ë£Œê¸°ê¸° ë“±", "icon": "ğŸ§¬", "tags": ["sector_healthcare"]},
                    {"id": "sector_any", "label": "íŠ¹ë³„íˆ ìƒê´€ì—†ë‹¤", "description": "ì„¹í„°ëŠ” ìƒê´€ì—†ê³  ì¡°ê±´ë§Œ ì¢‹ìœ¼ë©´ ëœë‹¤.", "icon": "ğŸ²", "tags": ["sector_any"]},
                ],
            },
        ]

    def _load_nl_category_mapping(self):
        """ìì—°ì–´ â†’ ìƒìœ„ íŒ©í„° ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ë¡œë“œ."""
        path = Path("/app/config/nl_category_mapping.json")
        if not path.exists():
            path = Path(__file__).parent.parent.parent / "config" / "nl_category_mapping.json"

        if not path.exists():
            print(f"WARNING: nl_category_mapping.json not found at {path}")
            self.nl_category_mapping = {}
            return

        try:
            data = json.loads(path.read_text(encoding="utf-8"))
            if isinstance(data, dict):
                self.nl_category_mapping = {k.upper(): v for k, v in data.items()}
                print(f"Loaded nl_category_mapping ({len(self.nl_category_mapping)} categories)")
            else:
                print(f"WARNING: nl_category_mapping.json has invalid format")
                self.nl_category_mapping = {}
        except Exception as e:
            print(f"ERROR: Failed to load nl_category_mapping.json: {e}")
            self.nl_category_mapping = {}

    def _load_config(self):
        """Load configuration."""
        config_file = Path(__file__).parent.parent / "config.yaml"
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        else:
            # Fallback config
            self.config = {
                "llm": {
                    "provider": LLM_PROVIDER,
                    "model": "mistral.mixtral-8x7b-instruct-v0:1",
                    "temperature": 0.7,
                    "max_tokens": 2000,
                    "region": "us-east-1"
                },
                "rag": {
                    "top_k": 3
                }
            }

    def _load_strategies(self):
        """Load strategies from prompts/strategies.json and build mappings."""
        path = Path("/app/prompts/strategies.json")
        if not path.exists():
            path = Path(__file__).parent.parent.parent / "prompts" / "strategies.json"

        strategies = []
        try:
            if path.exists():
                data = json.loads(path.read_text(encoding="utf-8"))
                strategies = data.get("strategies", [])
                print(f"Loaded {len(strategies)} strategies from strategies.json")
            else:
                print("strategies.json not found; using defaults")
        except Exception as e:
            print(f"Failed to load strategies.json: {e}")

        # Build mappings
        self.strategies = {s["id"]: s for s in strategies if "id" in s}
        # For recommendation scoring
        self.strategy_tags_mapping = {}
        for s in strategies:
            sid = s.get("id")
            if not sid:
                continue
            self.strategy_tags_mapping[sid] = {
                "strategy_id": sid,
                "strategy_name": s.get("name", sid),
                "summary": s.get("summary", ""),
                "tags": s.get("tags", []),
                "conditions": s.get("conditions_preview") or s.get("conditions") or [],
            }
        # For backtest templates
        self.strategy_backtest_templates = {}
        self.strategy_alias_map = {}
        for s in strategies:
            sid = s.get("id")
            if not sid:
                continue
            self.strategy_backtest_templates[sid] = {
                "strategy_name": s.get("name", sid),
                "buy_conditions": self._filter_valid_conditions(s.get("buy_conditions", [])),
                "sell_conditions": self._filter_valid_conditions(s.get("sell_conditions", [])),
            }
            alias_tokens = self._build_strategy_aliases(
                sid,
                s.get("name"),
                s.get("aliases", []),
            )
            self.strategy_alias_map[sid] = alias_tokens

    def _load_forbidden_patterns(self):
        """ê¸ˆì§€ íŒ¨í„´ì„ ì™¸ë¶€ ì„¤ì •ì—ì„œ ë¡œë“œ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)."""
        default_patterns = {
            "ì¢…ëª©_ì¶”ì²œ": [
                r"(.*?)(ì‚¼ì„±|SK|í˜„ëŒ€|LG|ì¹´ì¹´ì˜¤|ë„¤ì´ë²„|ë„¥ìŠ¨|ì—”ì”¨ì†Œí”„íŠ¸|ì…€íŠ¸ë¦¬ì˜¨|"
                r"NVIDIA|ì• í”Œ|í…ŒìŠ¬ë¼|ë§ˆì´í¬ë¡œì†Œí”„íŠ¸|êµ¬ê¸€|ì•ŒíŒŒë²³)\s*(ì¶”ì²œ|ì‚¬ì„¸ìš”|ë§¤ìˆ˜|ë§¤ë„|ì‚¬ë‹¬ë¼|íŒ”ì•„ì•¼)",
                r"(ì´ ì¢…ëª©|ì´ ì£¼ì‹).*?(ìƒìŠ¹|í•˜ë½|ì‚¬ì„¸ìš”|íŒ”ì•„ì•¼|ë§¤ìˆ˜)",
                r"(ê¼­|ë°˜ë“œì‹œ|ê¼­ê¼­|ì ê·¹)\s*(ì¶”ì²œ|ì¶”ì²œí•¨|í¬í•¨)",
            ],
            "ë§¤ë§¤_ì‹œì ": [
                r"(ì§€ê¸ˆ|í˜„ì¬|ìš”ì¦˜|í•´ì•¼|í•´ì•¼ í• )\s*(ë§¤ìˆ˜|ë§¤ë„|ì‚¬ì„¸ìš”|íŒ”ì•„ì•¼|íƒ€ì´ë°|ì‚¬ë‚˜|íŒŒë‚˜)",
                r"(ë§¤ìˆ˜|ë§¤ë„|ì‚¬ì•¼|íŒŒì•¼)\s*(í•˜ë‚˜|í• ê¹Œ|í• ì§€|í•´ì•¼|í•©ë‹ˆë‹¤)",
                r"(ë§¤ìˆ˜ê°€|ì ì •ê°€|ëª©í‘œê°€|ì†ì ˆ|ìµì ˆ)\s*(ì„¤ì •|í•˜ì„¸ìš”|í•´ì•¼)",
                r"(\d+ì›).*?(ì ì •|ë§ëŠ”|íƒ€ì´ë°)",
                r"(ì–¸ì œ|ì–´ë””ì„œ|ì–´ë–»ê²Œ)\s+(ë§¤ìˆ˜|ë§¤ë„|ì‚¬ì•¼|íŒŒì•¼)",
            ],
            "ìˆ˜ìµë¥ _ë³´ì¥": [
                r"(ë³´ì¥|í™•ì‹¤|í™•ì •|100%|ë¬´ì¡°ê±´)\s*(ìˆ˜ìµ|ì´ìµ|ìˆ˜ìµë¥ )",
                r"(ìˆ˜ìµ|ì´ìµ).*?(ì†ì‹¤|ìœ„í—˜).*?(ì—†|ì—†ìŒ)",
                r"(í•­ìƒ|ë°˜ë“œì‹œ)\s*(ìˆ˜ìµ)",
            ],
            "ê°œì¸í™”_ì¡°ì–¸": [
                r"(ë‹¹ì‹ |ë„ˆ|ë‹ˆ|ì €ëŠ”|ìš°ë¦¬ëŠ”|ìš°ë¦¬)\s*(ê²½ìš°|ìƒí™©|í™˜ê²½).*?(ì „ëµ|íˆ¬ì|ì¶”ì²œ|ì‚¬ëŠ”|ì‚¬ì„¸ìš”)",
                r"(ì›”|ë¶„ê¸°|ë…„)\s*(\d+)\s*(ë§Œì›|ì²œì›|ì›).*?(íˆ¬ì|ì‚¬ì„¸ìš”|í•´ì•¼)",
                r"(íŠ¹ë³„íˆ|ë§ì¶¤|íŠ¹í™”|ê°œì¸|ë”°ë¼).*?(íˆ¬ì|ì „ëµ|ì¶”ì²œ)",
            ],
            "ë¹„ì†ì–´": [
                r"(ì”¨ë°œ|ì‹œë°œ|ì¢†|ë³‘ì‹ |ê°œìƒˆë¼|ã……ã…‚|ã…ˆã„´|fuck|shit|bitch)",
            ],
            "ë„ë°•": [
                r"(ë„ë°•|ì¹´ì§€ë…¸|í† í† |ë°”ì¹´ë¼|ë£°ë ›|ë² íŒ…|ë°°íŒ…)",
            ],
        }

        path = Path("/app/config/forbidden_patterns.yaml")
        if not path.exists():
            path = Path(__file__).parent.parent.parent / "config" / "forbidden_patterns.yaml"

        if path.exists():
            try:
                data = yaml.safe_load(path.read_text(encoding="utf-8")) or {}
                if isinstance(data, dict) and data:
                    self.forbidden_patterns = data
                    print(f"Loaded forbidden patterns from {path}")
                    return
            except Exception as e:
                print(f"Failed to load forbidden_patterns.yaml: {e}")

        # fallback
        self.forbidden_patterns = default_patterns
        print("Using default forbidden patterns")

    def _init_components(self):
        """Initialize RAG, MCP, and LLM clients."""
        provider = self.config["llm"].get("provider", LLM_PROVIDER).lower()
        self.provider = provider

        # Initialize components regardless of provider first
        print(f"LLM Provider: {self.provider}")

        # Initialize FactorSync for Backend integration
        if FactorSync:
            self.factor_sync = FactorSync()
            print("FactorSync initialized - Backend integration enabled")

        # Initialize RAG retriever
        if RetrieverFactory:
            try:
                self.rag_retriever = RetrieverFactory.create_retriever(
                    retriever_type=os.getenv("RETRIEVER_TYPE"),
                    config=self.config.get("rag", {})
                )
                print("RAG Retriever initialized - Knowledge base loaded")
                
                # í—¬ìŠ¤ ì²´í¬
            except Exception as e:
                print(f"Warning: RAG Retriever initialization failed: {e}")
                self.rag_retriever = None

        # Initialize News retriever
        if NewsRetriever:
            backend_url = os.getenv("BACKEND_URL", "http://backend:8000/api/v1")
            self.news_retriever = NewsRetriever(backend_url)
            print(f"News Retriever initialized - Backend URL: {backend_url}")

        # Bedrock ì œê³µììš© LangChain ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        if self.provider == "bedrock":
            if not get_tools:
                print("ê²½ê³ : get_toolsë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return

            try:
                # 1. LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                print("Step 1: LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
                aws_region = os.getenv("AWS_REGION", self.config["llm"].get("region", "us-east-1"))

                if not ChatBedrock:
                    print("ê²½ê³ : ChatBedrockì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. langchain-awsë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
                    return

                # AWS Bedrockìœ¼ë¡œ Claude LLM ì´ˆê¸°í™”
                # Throttling ëŒ€ì‘: ì¬ì‹œë„ ì„¤ì • ì¶”ê°€
                import boto3
                from botocore.config import Config

                retry_config = Config(
                    retries={
                        'max_attempts': 3,  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì¤„ì„ (ê¸°ë³¸ 4 â†’ 3)
                        'mode': 'adaptive'  # ì ì‘í˜• ì¬ì‹œë„ (ì ì§„ì  ë°±ì˜¤í”„)
                    },
                    read_timeout=120,  # ì½ê¸° íƒ€ì„ì•„ì›ƒ ì¦ê°€
                    connect_timeout=10
                )

                # Bedrock í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§ì ‘ ìƒì„± (retry_config ì ìš©)
                bedrock_client = boto3.client(
                    service_name='bedrock-runtime',
                    region_name=aws_region,
                    config=retry_config
                )

                model_id = os.getenv("BEDROCK_MODEL_ID", self.config["llm"]["model"])
                inference_profile_id = (
                    os.getenv("BEDROCK_INFERENCE_PROFILE_ID")
                    or os.getenv("BEDROCK_INFERENCE_PROFILE_ARN")
                    or self.config["llm"].get("inference_profile_id")
                )
                model_kwargs = {
                    "temperature": self.config["llm"]["temperature"],
                    "max_tokens": self.config["llm"]["max_tokens"],
                }
                chatbedrock_kwargs = {
                    "client": bedrock_client,
                    "model_kwargs": model_kwargs,
                    "streaming": False,
                }
                # inference_profile_idë¥¼ ì‚¬ìš©í•˜ë©´ provider ì§€ì •ì´ í•„ìš”í•˜ë‹¤.
                if inference_profile_id:
                    chatbedrock_kwargs["provider"] = "anthropic"
                if inference_profile_id:
                    # For provisioned throughput deployments
                    chatbedrock_kwargs["inference_profile_id"] = inference_profile_id
                else:
                    chatbedrock_kwargs["model_id"] = model_id

                try:
                    self.llm_client = ChatBedrock(**chatbedrock_kwargs)
                except Exception as e:
                    # ValidationError (Pydantic) or TypeError (old langchain-aws versions)
                    error_msg = str(e)
                    if inference_profile_id and ("inference_profile_id" in error_msg or "extra fields not permitted" in error_msg):
                        # Older langchain-aws versions don't expose inference_profile_id;
                        # fall back to passing it as model_id so the client can still route.
                        print(f"âš ï¸  inference_profile_id ë¯¸ì§€ì› ê°ì§€ ({type(e).__name__}), model_idë¡œ fallback...")
                        chatbedrock_kwargs.pop("inference_profile_id", None)
                        chatbedrock_kwargs["model_id"] = inference_profile_id
                        chatbedrock_kwargs.setdefault("provider", "anthropic")
                        self.llm_client = ChatBedrock(**chatbedrock_kwargs)
                        print("âœ… ChatBedrockì„ inference_profile_id ëŒ€ì‹  model_idë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¬ë°œìƒ
                        raise

                target_id = inference_profile_id or model_id
                # ì—ëŸ¬ ë¡œê¹…ì„ ìœ„í•´ ë©”íƒ€ ë°ì´í„° ì €ì¥
                self.llm_region = aws_region
                self.llm_model_id = model_id
                self.llm_inference_profile_id = inference_profile_id
                self.llm_target_id = target_id

                print(
                    "Step 1 OK: AWS Bedrock ì‚¬ìš© - "
                    f"ë¦¬ì „: {aws_region}, ëŒ€ìƒ: {target_id}, "
                    f"env_model: {os.getenv('BEDROCK_MODEL_ID')}, "
                    f"env_profile: {os.getenv('BEDROCK_INFERENCE_PROFILE_ID') or os.getenv('BEDROCK_INFERENCE_PROFILE_ARN')}"
                )

                # 2. ë„êµ¬ ì´ˆê¸°í™”
                print("Step 2: ë„êµ¬ ì´ˆê¸°í™” ì¤‘...")
                tools = get_tools(
                    news_retriever=self.news_retriever,
                    factor_sync=self.factor_sync
                )
                print(f"Step 2 OK: ë„êµ¬ ì´ˆê¸°í™” ì™„ë£Œ: {[tool.name for tool in tools]}")

                # 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
                print("Step 3: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì¤‘...")
                prompt_specs = {
                    "assistant": {
                        "filename": "system_assistant.txt",
                        "fallback": "ë‹¹ì‹ ì€ ì •ëŸ‰ íˆ¬ì ìë¬¸ê°€ì´ì íˆ¬ì ê°œë…ì„ ì„¤ëª…í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
                    },
                    "ai_helper": {
                        "filename": "system_ai_helper.txt",
                        "fallback": "ë‹¹ì‹ ì€ ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ì„ ìƒì„±í•˜ê³  DSLì„ ë§Œë“œëŠ” AI í—¬í¼ì…ë‹ˆë‹¤."
                    },
                    "home_widget": {
                        "filename": "system_home_widget.txt",
                        "fallback": "ë‹¹ì‹ ì€ í™ˆ í™”ë©´ ìœ„ì ¯ì—ì„œ ê°„ê²°í•˜ê²Œ ê¸ˆìœµ ì§ˆë¬¸ì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
                    },
                }
                self.system_prompts = {}
                for mode, spec in prompt_specs.items():
                    self.system_prompts[mode] = self._load_system_prompt_content(
                        spec["filename"],
                        spec["fallback"]
                    )
                    print(f"  - {mode} í”„ë¡¬í”„íŠ¸ {len(self.system_prompts[mode])}ì ë¡œë“œ")
                print("Step 3 OK: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ")

                # 4. Claude ë„êµ¬ í˜¸ì¶œ í”„ë¡¬í”„íŠ¸/ì—ì´ì „íŠ¸ ìƒì„±
                print("Step 4: Claude í”„ë¡¬í”„íŠ¸ ë° AgentExecutor ìƒì„± ì¤‘...")
                self.agent_executors = {}
                for mode, system_prompt in self.system_prompts.items():
                    prompt_template = ChatPromptTemplate.from_messages([
                        (
                            "system",
                            system_prompt
                            + "\n\ní•„ìš”í•  ë•Œ ë‹¤ìŒ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                            + "\n\n{agent_scratchpad}"
                        ),
                        MessagesPlaceholder("chat_history"),
                        ("user", "ì°¸ê³ ìë£Œ:\n{context}\n\nì§ˆë¬¸: {input}"),
                    ])
                    agent = create_tool_calling_agent(self.llm_client, tools, prompt_template)
                    executor = AgentExecutor(
                        agent=agent,
                        tools=tools,
                        verbose=False,
                        return_intermediate_steps=True,
                        handle_parsing_errors=True,
                        max_iterations=5
                    )
                    self.agent_executors[mode] = executor
                    print(f"  - {mode} AgentExecutor ìƒì„± ì™„ë£Œ")
                print("Step 4 OK: ëª¨ë“  AgentExecutor ìƒì„± ì™„ë£Œ")

                print("âœ… LangChain AgentExecutor ìƒì„± ì„±ê³µ")
            except Exception as e:
                print(f"âŒ LangChain ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
        else:
            print(f"ê²½ê³ : ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ê±´ë„ˆëœ€. ì œê³µì={self.provider}, get_tools={get_tools is not None}")

    async def handle(
        self,
        message: str,
        session_id: Optional[str] = None,
        answer: Optional[dict] = None,
        client_type: Optional[str] = "assistant"
    ) -> dict:
        """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

        Args:
            message: ì‚¬ìš©ì ì…ë ¥
            session_id: ì„ íƒì‚¬í•­ ì„¸ì…˜ ID
            answer: ì„¤ë¬¸ ì‘ë‹µ (ì„ íƒì‚¬í•­)

        Returns:
            ì‘ë‹µ ë”•ì…”ë„ˆë¦¬
        """
        if session_id is None:
            session_id = str(uuid.uuid4())

        # client_typeì´ ëª…ì‹œë˜ì§€ ì•Šì•˜ê±°ë‚˜ "assistant"ì¼ ê²½ìš° ìë™ ë¼ìš°íŒ…
        if not client_type or client_type.lower() == "assistant":
            client_type = self._route_client_type(message)
            print(f"[AUTO-ROUTING] '{message[:50]}...' -> {client_type}")
        else:
            client_type = client_type.lower()

        # ìœ íš¨ì„± ê²€ì¦
        if client_type not in ("assistant", "ai_helper", "home_widget"):
            client_type = "assistant"

        # ì„¤ë¬¸/ì „ëµ ì¶”ì²œ í”Œë¡œìš° (ui_language)
        if answer or (client_type == "assistant" and self._is_strategy_request(message)):
            return await self._handle_questionnaire_flow(session_id, answer, message)

        if self._is_simple_greeting(message):
            return {
                "answer": self.DEFAULT_GREETING_RESPONSE,
                "intent": "greeting",
                "session_id": session_id,
                "sources": []
            }

        if client_type == "home_widget":
            # ë¨¼ì € shortcut ì²˜ë¦¬ ì‹œë„ (ë‰´ìŠ¤/ìŠ¤í¬ë¦¬ë‹ ë“±)
            home_widget_response = await self._handle_home_widget_shortcuts(message)
            if home_widget_response:
                home_widget_response["session_id"] = session_id
                return home_widget_response
            # shortcutì´ ì—†ìœ¼ë©´ home_widget í”„ë¡¬í”„íŠ¸ë¡œ ì¼ë°˜ ì²˜ë¦¬
            # (ê³„ì† ì§„í–‰í•˜ì—¬ _generate_response_langchainì—ì„œ home_widget ì—ì´ì „íŠ¸ ì‚¬ìš©)

        # ë„ë©”ì¸(ê¸ˆìœµ/íˆ¬ì) í•„í„° ë¹„í™œì„±í™”ë¨

        # ë‰´ìŠ¤ ìš”ì²­ì¸ë° í‚¤ì›Œë“œê°€ ë¶€ì¡±í•œ ê²½ìš° ì‚¬ì „ ì•ˆë‚´
        news_hint = self._needs_news_keyword(message)
        if news_hint:
            return {
                "answer": news_hint,
                "intent": "news_keyword_required",
                "session_id": session_id,
                "sources": []
            }

        # 0. ì •ì±… ê²€ì‚¬ (íˆ¬ì ì¡°ì–¸ ê¸ˆì§€ ì •ì±…)
        policy_violation = self._check_investment_advisory_policy(message, session_id=session_id)
        if policy_violation:
            return {
                "answer": policy_violation,
                "intent": "policy_violation",
                "session_id": session_id,
                "sources": []
            }

        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ê¸°ë°˜ ê°„ë‹¨ DSL ìƒì„± (ì´ˆë³´ì ìì—°ì–´ â†’ ìƒìœ„ ì¹´í…Œê³ ë¦¬)
        category_response = self._maybe_handle_category_mapping(message)
        if category_response:
            category_response["session_id"] = session_id
            return category_response

        # ë‰´ìŠ¤/í…Œë§ˆ ìš”ì²­ì¸ë° ë‰´ìŠ¤/í…Œë§ˆ ì„œë¹„ìŠ¤ê°€ ì—†ìœ¼ë©´ ì¦‰ì‹œ í…œí”Œë¦¿í˜• ì•ˆë‚´ë¡œ ì‘ë‹µ
        self._ensure_news_retriever()
        if self._is_news_theme_request(message) and not self.news_retriever:
            unavailable_answer = self._format_news_unavailable(message)
            return {
                "answer": unavailable_answer,
                "intent": "news_unavailable",
                "session_id": session_id,
                "sources": []
            }

        # 1. Classify intent
        intent = await self._classify_intent(message)
        if client_type == "ai_helper" and intent not in {"dsl_generation", "backtest_configuration", "explain"}:
            intent = "dsl_generation"

        # 2. Intentì— ë”°ë¼ ë‹¤ë¥¸ í•¸ë“¤ëŸ¬ í˜¸ì¶œ
        if intent == 'dsl_generation':
            response = await self._handle_dsl_mode(message, session_id)
        elif intent == 'explain':
            response = await self._handle_explain_mode(message, session_id, client_type)
        else:
            # ê¸°ì¡´ í†µí•© í”Œë¡œìš° (recommend, general ë“±)
            # home_widgetì€ ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ RAG ê²€ìƒ‰ ìƒëµ
            if client_type == "home_widget":
                context = ""
            else:
                context = await self._retrieve_context(message, intent)

            # ë‰´ìŠ¤/í…Œë§ˆ í‚¤ì›Œë“œ ê°ì§€ ì‹œ ê°•ì œë¡œ ë‰´ìŠ¤ + ê°ì„± ë¶„ì„ ë¨¼ì € ìˆ˜í–‰
            news_context = ""
            if self._is_news_theme_request(message) and self.news_retriever:
                news_context = await self._fetch_news_for_context(message)
                sentiment_context = await self._fetch_sentiment_for_context(message)

                combined_context = ""
                if news_context:
                    combined_context += f"[ìµœì‹  ë‰´ìŠ¤ ì •ë³´]\n{news_context}"
                if sentiment_context:
                    combined_context += f"\n\n[ê°ì„± ë¶„ì„ ë°ì´í„°]\n{sentiment_context}"

                if combined_context:
                    context = f"{context}\n\n{combined_context}" if context else combined_context

            if intent == 'backtest_configuration':
                response = self._handle_backtest_configuration(message, session_id)
            else:
                response = await self._generate_response_langchain(
                    message, intent, context, session_id, client_type
                )

        response["session_id"] = session_id
        return response

    def _is_simple_greeting(self, message: str) -> bool:
        if not message:
            return False
        plain = message.strip().lower()
        return plain in self.GREETING_KEYWORDS

    def _is_strategy_request(self, message: str) -> bool:
        """ì „ëµ ì¶”ì²œ ì„¤ë¬¸ì„ ì‹œì‘í• ì§€ ì—¬ë¶€ íŒë‹¨."""
        msg = (message or "").lower()
        triggers = ["ì „ëµ ì¶”ì²œ", "ì¶”ì²œë°›ê³  ì‹¶ì–´ìš”", "ì¶”ì²œ í•´ì¤˜", "ì„¤ë¬¸", "íˆ¬ì ì„±í–¥"]
        return any(t in msg for t in triggers) or msg.strip() == ""

    def _route_client_type(self, message: str) -> str:
        """ë©”ì‹œì§€ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ client_typeì„ ìë™ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤.

        ìš°ì„ ìˆœìœ„:
        1. AI_HELPER - í–‰ë™ ìš”ì²­ (ì¡°ê±´ ë§Œë“¤ê¸°, DSL ìƒì„±, ì „ëµ ì ìš© ë“±)
        2. ASSISTANT - ê°œë… ì„¤ëª… ìš”ì²­ (ë­ì•¼, ì˜ë¯¸, ì°¨ì´, ì„¤ëª… ë“±)
        3. HOME_WIDGET - ì§§ì€ ì§ˆë¬¸, ìš”ì•½ ìš”ì²­
        4. ASSISTANT - ë‚˜ë¨¸ì§€ ëª¨ë“  ê²½ìš° (ê¸°ë³¸ê°’)

        Args:
            message: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€

        Returns:
            "ai_helper", "home_widget", ë˜ëŠ” "assistant"
        """
        if not message:
            return "assistant"

        text = message.strip()

        # === 1ìˆœìœ„: AI HELPER ê·œì¹™ (í–‰ë™ ìš”ì²­) ===

        # ì˜ˆì™¸: ë°±í…ŒìŠ¤íŠ¸ ê°œë… ì§ˆë¬¸ì€ í—¬í¼ê°€ ì•„ë‹˜
        helper_exception_patterns = [
            r"ë°±í…ŒìŠ¤íŠ¸.*(ë¬´ì—‡|ë­|ì™œ|ì–´ë–»ê²Œ|ì•Œì•„ì•¼|í•„ìš”|ì˜ë¯¸|ì„¤ëª…)",
        ]

        is_helper_exception = False
        for pattern in helper_exception_patterns:
            if re.search(pattern, text):
                is_helper_exception = True
                break

        if not is_helper_exception:
            # AI HELPERë¡œ ë³´ë‚´ì•¼ í•˜ëŠ” íŒ¨í„´ë“¤ (ë§¤ìš° ëª…í™•í•œ DSL ìƒì„± ìš”ì²­ë§Œ)
            helper_patterns = [
                # êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ê°€ ìˆëŠ” ì¡°ê±´
                r"(<=|>=|<|>|%|ì´ìƒ|ì´í•˜).*(ë§¤ìˆ˜|ë§¤ë„)",
                r"\d+.*(ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ).*(ë§¤ìˆ˜|ë§¤ë„)",

                # íŒ©í„° + ì¡°ê±´ ëª…ì‹œ
                r"(PER|PBR|ROE|RSI|MACD|ë³¼ë¦°ì €).*(ì¡°ê±´|ë§¤ìˆ˜|ë§¤ë„)",

                # ëª…í™•í•œ ì¡°ê±´/DSL ìƒì„± ìš”ì²­ (ì „ëµëª… ì—†ì´)
                r"^(ì¡°ê±´|DSL).*(ë§Œë“¤|ìƒì„±|í•´ì¤˜)",
                r"^(ë£°|ê·œì¹™).*(ë§Œë“¤|ìƒì„±)",

                # ë°±í…ŒìŠ¤íŠ¸ + êµ¬ì²´ì  ìš”ì²­
                r"ë°±í…ŒìŠ¤íŠ¸.*(ì¡°ê±´|ë§Œë“¤|ìƒì„±)",
            ]

            for pattern in helper_patterns:
                if re.search(pattern, text):
                    return "ai_helper"

        # === 2ìˆœìœ„: ASSISTANT ê°œë… ì„¤ëª… íŒ¨í„´ (ì§§ì€ ë¬¸ì¥ì´ë¼ë„ ì„¤ëª… ìš”ì²­ì´ë©´ assistant) ===

        # íˆ¬ì ê±°ì¥/ì „ëµëª… íŒ¨í„´ (ì§§ì•„ë„ assistantë¡œ)
        strategy_investor_patterns = [
            r"(ì›Œë Œë²„í•|ì›Œë Œ|ë²„í•|buffett)",
            r"(í”¼í„°ë¦°ì¹˜|í”¼í„°|ë¦°ì¹˜|lynch)",
            r"(ë²¤ìë¯¼ê·¸ë ˆì´ì—„|ë²¤ìë¯¼|ê·¸ë ˆì´ì—„|graham)",
            r"(ë ˆì´ë‹¬ë¦¬ì˜¤|ë ˆì´|ë‹¬ë¦¬ì˜¤|dalio)",
            r"(í•„ë¦½í”¼ì…”|í•„ë¦½|í”¼ì…”|fisher)",
            r"ì „ëµ",  # "ì „ëµ" í‚¤ì›Œë“œ
            r"(ê°€ì¹˜íˆ¬ì|ì„±ì¥íˆ¬ì|ëª¨ë©˜í…€íˆ¬ì|ë°°ë‹¹íˆ¬ì)",
        ]

        for pattern in strategy_investor_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return "assistant"

        explanation_patterns = [
            r"(ë­ì•¼|ë­”ë°|ë¬´ì—‡|ë­”ì§€|ë­”ê°€ìš”|ë­˜ê¹Œ)",  # "PERì´ ë­ì•¼?"
            r"(ì˜ë¯¸|ëœ»|ê°œë…|ì •ì˜)(\?|$)",  # "RSI ì˜ë¯¸?"
            r"(ì„¤ëª…|ì•Œë ¤|ê°€ë¥´ì³|ì•Œì•„ì•¼|ì´í•´)",  # "ì‰½ê²Œ ì„¤ëª…í•´ì¤˜"
            r"(ì°¨ì´|ë¹„êµ|ë‹¤ë¥¸ì )",  # "ëª¨ë©˜í…€ê³¼ ê°€ì¹˜ ì „ëµ ì°¨ì´"
            r"(ì–´ë–¤|ë¬´ìŠ¨).*ì „ëµ",  # "ì–´ë–¤ ì „ëµì´ ë§ì•„?"
            r"í•˜ê¸° ì „ì—",  # "ë°±í…ŒìŠ¤íŠ¸ í•˜ê¸° ì „ì—"
            r"(\?|ï¼Ÿ).*\?",  # ë¬¼ìŒí‘œê°€ 2ê°œ ì´ìƒ
        ]

        for pattern in explanation_patterns:
            if re.search(pattern, text):
                return "assistant"

        # === 3ìˆœìœ„: HOME WIDGET ê·œì¹™ (ì§§ì€ ì§ˆë¬¸/ìš”ì•½) ===

        # 20ì ì´í•˜ì´ë©´ì„œ ê°„ë‹¨í•œ ë¬¸ì¥ (? í•˜ë‚˜ë§Œ ìˆê±°ë‚˜, ë‹¨ì–´ 2-3ê°œ)
        if len(text) <= 20:
            # ë‹¨ì–´ ê°œìˆ˜ í™•ì¸
            words = re.findall(r'\S+', text)
            if len(words) <= 3:
                return "home_widget"

        # ìš”ì•½/ê°„ë‹¨ ìš”ì²­ í‚¤ì›Œë“œ
        widget_patterns = [
            r"(ìš”ì•½|ê°„ë‹¨íˆ|í•œì¤„|ì§§ê²Œ|í•µì‹¬ë§Œ)",
        ]

        for pattern in widget_patterns:
            if re.search(pattern, text):
                return "home_widget"

        # === 4ìˆœìœ„: ASSISTANT (ê¸°ë³¸ê°’) ===
        return "assistant"

    async def _handle_home_widget_shortcuts(self, message: str) -> Optional[dict]:
        """í™ˆ ìœ„ì ¯ì—ì„œ ìì£¼ ìš”ì²­ë˜ëŠ” ë‹¨ìˆœ ì‘ë‹µ ì²˜ë¦¬."""
        if not message:
            return None

        # 1) íŒ©í„°/ìŠ¤í¬ë¦¬ë‹ ìš”ì²­ì„ ê°„ë‹¨ í…œí”Œë¦¿ìœ¼ë¡œ ì²˜ë¦¬ (ì¢…ëª©ëª… ê¸ˆì§€)
        if self._is_home_widget_screening_request(message):
            per_threshold = self._extract_number(message, default=10)
            buy_conditions: List[Dict[str, Any]] = [
                {"factor": "PER", "params": [], "operator": "<=", "right_factor": None, "right_params": [], "value": per_threshold},
                {"factor": "revenue_cagr_3y", "params": [], "operator": ">", "right_factor": None, "right_params": [], "value": 10},
                {"factor": "eps_growth_rate", "params": [], "operator": ">", "right_factor": None, "right_params": [], "value": 10},
                {"factor": "ROE", "params": [], "operator": ">", "right_factor": None, "right_params": [], "value": 10},
                {"factor": "DebtRatio", "params": [], "operator": "<", "right_factor": None, "right_params": [], "value": 150},
            ]

            answer = (
                "## ìš”ì•½\n"
                f"PER<={per_threshold}, ì„±ì¥ë¥ >10%, ROE>10%, ë¶€ì±„ë¹„ìœ¨<150% ì¡°ê±´ì„ ë²„íŠ¼ìœ¼ë¡œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
                "### ë‹¤ìŒ ë‹¨ê³„\n"
                "- ë§¤ìˆ˜/ë§¤ë„ ì¡°ê±´ ë²„íŠ¼ìœ¼ë¡œ ë°”ë¡œ ì ìš©\n"
                "- ìˆ˜ì¹˜ ì¡°ì •ì´ í•„ìš”í•˜ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”"
            )

            return {
                "answer": answer,
                "intent": "dsl_suggestion",
                "sources": [],
                "backtest_conditions": {"buy": buy_conditions, "sell": []},
            }

        # 2) ë‰´ìŠ¤/ì‹œì¥ ìš”ì•½ ìš”ì²­ ì²˜ë¦¬
        if not self._is_home_widget_news_request(message):
            return None

        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°)
        search_query = message.strip()
        noise_words = ["í…Œë§ˆ", "ë™í–¥", "ë‰´ìŠ¤", "ì•Œë ¤ì¤˜", "í™•ì¸í•´ì¤˜", "ìµœê·¼", "ì˜", "ì„", "ë¥¼", "ì´", "ê°€"]
        for word in noise_words:
            search_query = search_query.replace(word, " ")
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        import re
        search_query = re.sub(r'\s+', ' ', search_query).strip()

        if not search_query:
            search_query = message.strip()

        print(f"[ë‰´ìŠ¤ ê²€ìƒ‰] ì›ë³¸: '{message}' â†’ ê²€ìƒ‰ì–´: '{search_query}'")

        news_items: List[Dict[str, Any]] = []
        if self.news_retriever:
            try:
                news_items = await self.news_retriever.search_news_by_keyword(search_query, max_results=3)
                print(f"[ë‰´ìŠ¤ ê²€ìƒ‰] ê²°ê³¼ {len(news_items)}ê±´")
            except Exception as exc:
                print(f"[WARN] í™ˆ ìœ„ì ¯ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {exc}")

        if not news_items:
            return {
                "answer": "## ìš”ì•½\ní•´ë‹¹ ì¢…ëª©ì˜ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n### ë‹¤ìŒ ë‹¨ê³„\n- ë‰´ìŠ¤ íƒ­ì—ì„œ ì§ì ‘ ìµœì‹  ê¸°ì‚¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n- ë‹¤ë¥¸ ì¢…ëª©ì´ë‚˜ ì§€í‘œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
                "intent": "news_summary",
                "sources": []
            }

        primary = news_items[0]
        title = primary.get("title") or "ìµœì‹  ë‰´ìŠ¤"
        published = (
            primary.get("publishedAt")
            or (primary.get("date") or {}).get("display")
            or ""
        )
        snippet = primary.get("summary") or primary.get("content") or ""
        snippet = snippet.strip().replace("\n", " ")
        if len(snippet) > 160:
            snippet = snippet[:157] + "..."

        main_sentence = f"{title}"
        if published:
            main_sentence += f" ({published})"
        if snippet:
            main_sentence += f" - {snippet}"

        extras = []
        for item in news_items[1:3]:
            sub_title = item.get("title")
            if not sub_title:
                continue
            sub_published = (
                item.get("publishedAt")
                or (item.get("date") or {}).get("display")
                or ""
            )
            if sub_published:
                extras.append(f"{sub_title} ({sub_published})")
            else:
                extras.append(sub_title)

        if extras:
            secondary_sentence = f"ì¶”ê°€ ê¸°ì‚¬: {', '.join(extras)}."
        else:
            secondary_sentence = "ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ê¸°ì—…ì´ ìˆìœ¼ë©´ ì•Œë ¤ì£¼ì„¸ìš”."

        answer = (
            f"## ìš”ì•½\n{main_sentence} {secondary_sentence}\n\n"
            "### ë‹¤ìŒ ë‹¨ê³„\n"
            "- ë‰´ìŠ¤ íƒ­ì—ì„œ ë‚˜ë¨¸ì§€ ê¸°ì‚¬ì™€ ì„¸ë¶€ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.\n"
            "- ê¶ê¸ˆí•œ ë‹¤ë¥¸ ì¢…ëª©ì´ë‚˜ ì§€í‘œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
        )

        return {
            "answer": answer,
            "intent": "news_summary",
            "sources": []
        }

    def _extract_number(self, message: str, default: float = 10) -> float:
        """ë©”ì‹œì§€ì—ì„œ ìˆ«ìë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜."""
        import re
        numbers = re.findall(r'\d+(?:\.\d+)?', message)
        if numbers:
            return float(numbers[0])
        return default

    def _is_home_widget_screening_request(self, message: str) -> bool:
        """í™ˆ ìœ„ì ¯ ìŠ¤í¬ë¦¬ë‹ ìš”ì²­ ì—¬ë¶€ íŒë‹¨ (íŠ¹ì • í‚¤ì›Œë“œ ê¸°ë°˜)."""
        if not message:
            return False
        lower = message.lower()
        # ë‹¨ìˆœ ìŠ¤í¬ë¦¬ë‹ í‚¤ì›Œë“œ (íŒ©í„° ì¡°í•©ì€ category_mappingì—ì„œ ì²˜ë¦¬)
        keywords = ["per", "pbr", "roe", "ìŠ¤í¬ë¦¬ë‹", "ì¡°ê±´ ì°¾", "í•„í„°ë§"]
        return any(kw in lower for kw in keywords)

    def _is_home_widget_news_request(self, message: str) -> bool:
        if not message:
            return False
        lower = message.lower()
        keywords = ["ë‰´ìŠ¤", "ë™í–¥", "headline", "í…Œë§ˆ", "ì‹œì¥", "ìµœê·¼", "íŠ¸ë Œë“œ", "ì´ìŠˆ"]
        return any(kw in lower for kw in keywords)

    def _is_news_theme_request(self, message: str) -> bool:
        """ë‰´ìŠ¤/í…Œë§ˆ ìš”ì²­ ì—¬ë¶€ íŒë‹¨ (ì¼ë°˜ ëª¨ë“œìš©)"""
        if not message:
            return False
        lower = message.lower()
        keywords = ["ë‰´ìŠ¤", "ë™í–¥", "headline", "í…Œë§ˆ", "ì‹œì¥", "ìµœê·¼", "íŠ¸ë Œë“œ", "ì´ìŠˆ"]
        return any(kw in lower for kw in keywords)

    async def _fetch_news_for_context(self, message: str) -> str:
        """ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì„œ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë°˜í™˜"""
        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        search_query = message.strip()
        noise_words = ["í…Œë§ˆ", "ë™í–¥", "ë‰´ìŠ¤", "ì•Œë ¤ì¤˜", "í™•ì¸í•´ì¤˜", "ìµœê·¼", "ì˜", "ì„", "ë¥¼", "ì´", "ê°€"]
        for word in noise_words:
            search_query = search_query.replace(word, " ")
        import re
        search_query = re.sub(r'\s+', ' ', search_query).strip()

        # ê²€ìƒ‰ì–´ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
        if not search_query or len(search_query) < 2:
            search_query = message.strip()

        # ITëŠ” ì •ë³´ê¸°ìˆ ë¡œ í™•ì¥
        if search_query.lower() in ["it", "i t"]:
            search_query = "ì •ë³´ê¸°ìˆ "

        print(f"[ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰] ì›ë³¸: '{message}' â†’ ê²€ìƒ‰ì–´: '{search_query}'")

        try:
            news_items = await self.news_retriever.search_news_by_keyword(search_query, max_results=5)
            print(f"[ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰] ê²°ê³¼ {len(news_items)}ê±´")

            if not news_items:
                return ""

            # ë‰´ìŠ¤ë¥¼ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜
            news_lines = []
            for idx, item in enumerate(news_items[:5], 1):
                title = item.get("title", "ì œëª© ì—†ìŒ")
                summary = item.get("summary") or item.get("content") or ""
                summary = summary[:150] if summary else ""
                published = item.get("publishedAt") or item.get("date", {}).get("display") or ""

                news_lines.append(f"{idx}. {title}")
                if published:
                    news_lines.append(f"   ë°œí–‰ì¼: {published}")
                if summary:
                    news_lines.append(f"   ìš”ì•½: {summary}")

            return "\n".join(news_lines)
        except Exception as exc:
            print(f"[WARN] ë‰´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {exc}")
            return ""

    async def _fetch_sentiment_for_context(self, message: str) -> str:
        """ê°ì„± ë¶„ì„ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•´ì„œ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë°˜í™˜"""
        if not self.sentiment_service:
            return ""

        print(f"[ê°ì„± ë¶„ì„ ê²€ìƒ‰] í…Œë§ˆë³„ ê°ì„± ë°ì´í„° ì¡°íšŒ")

        try:
            # í…Œë§ˆë³„ ê°ì„± ì¸ì‚¬ì´íŠ¸ ê°€ì ¸ì˜¤ê¸°
            insights = await self.sentiment_service.get_theme_sentiment_insights(limit=10)
            print(f"[ê°ì„± ë¶„ì„ ê²€ìƒ‰] ê²°ê³¼ {len(insights)}ê±´")

            if not insights:
                return ""

            # ê°ì„± ë°ì´í„°ë¥¼ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜
            sentiment_lines = []
            for insight in insights[:10]:
                theme_name = insight.get("theme_name", "ì•Œ ìˆ˜ ì—†ëŠ” í…Œë§ˆ")
                sentiment_score = insight.get("sentiment_score", 0)
                news_count = insight.get("news_count", 0)
                interpretation = insight.get("interpretation", "")

                # ê¸ì •/ë¶€ì • íŒë‹¨
                if sentiment_score > 0.2:
                    sentiment_label = "ê¸ì •ì "
                elif sentiment_score < -0.2:
                    sentiment_label = "ë¶€ì •ì "
                else:
                    sentiment_label = "ì¤‘ë¦½ì "

                sentiment_lines.append(
                    f"- {theme_name}: {sentiment_label} (ì ìˆ˜: {sentiment_score:.2f}, ë‰´ìŠ¤ {news_count}ê±´)"
                )
                if interpretation:
                    sentiment_lines.append(f"  í•´ì„: {interpretation}")

            return "\n".join(sentiment_lines)
        except Exception as exc:
            print(f"[WARN] ê°ì„± ë¶„ì„ ê²€ìƒ‰ ì‹¤íŒ¨: {exc}")
            return ""

    def _detect_nl_categories(self, message: str) -> List[str]:
        """ìì—°ì–´ ë¬¸ì¥ì—ì„œ ìƒìœ„ íŒ©í„° ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œ."""
        if not message or not self.nl_category_mapping:
            return []
        msg_lower = message.lower()
        detected = []
        for category, keywords in self.nl_category_mapping.items():
            for kw in keywords:
                if kw.lower() in msg_lower:
                    detected.append(category)
                    break
        return detected

    def _build_category_conditions(self, categories: List[str]) -> List[Dict[str, Any]]:
        """ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ DSL ì¡°ê±´ ë¬¶ìŒ ìƒì„±."""
        preset: Dict[str, List[Dict[str, Any]]] = {
            "VALUE": [
                {"factor": "PER", "params": [], "operator": "<=", "right_factor": None, "right_params": [], "value": 10},
                {"factor": "PBR", "params": [], "operator": "<=", "right_factor": None, "right_params": [], "value": 1.0},
            ],
            "QUALITY": [
                {"factor": "ROE", "params": [], "operator": ">=", "right_factor": None, "right_params": [], "value": 15},
                {"factor": "OperatingProfitMargin", "params": [], "operator": ">=", "right_factor": None, "right_params": [], "value": 10},
            ],
            "GROWTH": [
                {"factor": "revenue_cagr_3y", "params": [], "operator": ">", "right_factor": None, "right_params": [], "value": 10},
                {"factor": "eps_growth_rate", "params": [], "operator": ">", "right_factor": None, "right_params": [], "value": 10},
            ],
            "MOMENTUM": [
                {"factor": "RET_60D", "params": [], "operator": ">=", "right_factor": None, "right_params": [], "value": 0.05},
            ],
            "STABILITY": [
                {"factor": "VOLATILITY_60D", "params": [], "operator": "<=", "right_factor": None, "right_params": [], "value": 0.2},
            ],
            "DIVIDEND": [
                {"factor": "DividendYield", "params": [], "operator": ">=", "right_factor": None, "right_params": [], "value": 3},
            ],
        }
        conditions: List[Dict[str, Any]] = []
        for cat in categories:
            conditions.extend(preset.get(cat, []))
        return conditions

    def _maybe_handle_category_mapping(self, message: str) -> Optional[dict]:
        """ìì—°ì–´ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ìœ¼ë¡œ ì¦‰ì‹œ DSL ì¡°ê±´ì„ ë°˜í™˜."""
        categories = self._detect_nl_categories(message)
        if not categories:
            return None

        conditions = self._build_category_conditions(categories)
        if not conditions:
            return None

        cat_text = ", ".join(categories)
        lines = [f"- {c['factor']} {c['operator']} {c['value']}" for c in conditions]
        answer = (
            "## ìš”ì•½\n"
            f"{cat_text} ê¸°ì¤€ìœ¼ë¡œ ìŠ¤í¬ë¦¬ë‹ ì¡°ê±´ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.\n\n"
            "### ì¡°ê±´ì‹\n" + "\n".join(lines) + "\n\n"
            "### ë‹¤ìŒ ë‹¨ê³„\n- ë§¤ìˆ˜/ë§¤ë„ ì¡°ê±´ì— ì¶”ê°€ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì ìš©í•˜ì„¸ìš”. \n"
        )

        return {
            "answer": answer,
            "intent": "dsl_suggestion",
            "sources": [],
            "backtest_conditions": {
                "buy": conditions,
                "sell": []
            }
        }

    async def _handle_questionnaire_flow(self, session_id: str, answer: Optional[dict], message: str) -> dict:
        """5ë¬¸í•­ ì„¤ë¬¸ â†’ ì „ëµ ì¶”ì²œ UI Language ìƒì„±."""
        # ì„¸ì…˜ ì´ˆê¸°í™”
        state = self.session_state.setdefault(session_id, {
            "current": 1,
            "answers": {},
            "completed": False,
        })

        # ì‘ë‹µ ì²˜ë¦¬
        if answer and "question_id" in answer and "option_id" in answer:
            state["answers"][answer["question_id"]] = answer["option_id"]
            state["current"] += 1

        total = len(self.questions)

        # ëª¨ë“  ì§ˆë¬¸ ì™„ë£Œ â†’ ì¶”ì²œ ìƒì„±
        if state["current"] > total:
            recs = self._build_recommendations(state["answers"])
            state["completed"] = True
            return {
                "answer": "ê³ ê°ë‹˜ì˜ íˆ¬ì ì„±í–¥ì„ ë¶„ì„í•œ ê²°ê³¼, ë‹¤ìŒ ì „ëµì„ ì¶”ì²œë“œë ¤ìš”!",
                "intent": "strategy_recommendation_complete",
                "session_id": session_id,
                "ui_language": {
                    "type": "strategy_recommendation",
                    "recommendations": recs,
                    "user_profile_summary": self._build_profile_summary(state["answers"]),
                },
            }

        # ë‹¤ìŒ ì§ˆë¬¸ ë Œë”ë§
        question = sorted(self.questions, key=lambda q: q["order"])[state["current"] - 1]
        progress = int(((state["current"] - 1) / total) * 100)

        return {
            "answer": f"ì§ˆë¬¸ {state['current']}/{total}: {question['text']}",
            "intent": "questionnaire_progress" if state["current"] > 1 else "questionnaire_start",
            "session_id": session_id,
            "ui_language": {
                "type": "questionnaire_progress" if state["current"] > 1 else "questionnaire_start",
                "total_questions": total,
                "current_question": state["current"],
                "progress_percentage": progress,
                "question": question,
            },
        }

    def _collect_user_tags(self, answers: Dict[str, str]) -> List[str]:
        """ì„ íƒëœ ì˜µì…˜ì—ì„œ íƒœê·¸ ìˆ˜ì§‘."""
        tags: List[str] = []
        for q in self.questions:
            qid = q["question_id"]
            if qid not in answers:
                continue
            opt = next((o for o in q["options"] if o["id"] == answers[qid]), None)
            if opt:
                tags.extend(opt.get("tags", []))
        return tags

    def _build_recommendations(self, answers: Dict[str, str]) -> List[dict]:
        """íƒœê·¸ ê²¹ì¹¨ ê¸°ë°˜ ì¶”ì²œ ìƒìœ„ 3ê°œ."""
        user_tags = set(self._collect_user_tags(answers))
        scored = []
        for sid, meta in self.strategy_tags_mapping.items():
            stags = set(meta.get("tags", []))
            score = len(user_tags & stags) / (len(stags) or 1)
            scored.append((score, meta))
        scored.sort(key=lambda x: x[0], reverse=True)
        top = scored[:3]
        recs = []
        for rank, (score, meta) in enumerate(top, start=1):
            recs.append({
                "rank": rank,
                "strategy_id": meta["strategy_id"],
                "strategy_name": meta["strategy_name"],
                "summary": meta.get("summary", ""),
                "match_score": round(score, 2),
                "match_percentage": int(score * 100),
                "match_reasons": list(user_tags & set(meta.get("tags", []))),
                "tags": meta.get("tags", []),
                "conditions_preview": meta.get("conditions", []),
                "icon": meta.get("icon", "â­"),
                "badge": meta.get("badge"),
            })
        return recs

    def _build_profile_summary(self, answers: Dict[str, str]) -> dict:
        """ì„ íƒì§€ ë¼ë²¨ì„ ìš”ì•½ìœ¼ë¡œ ë³€í™˜."""
        summary = {
            "investment_period": self._get_label("investment_period", answers.get("investment_period")),
            "investment_style": self._get_label("investment_style", answers.get("investment_style")),
            "risk_tolerance": self._get_label("risk_tolerance", answers.get("risk_tolerance")),
            "dividend_preference": self._get_label("dividend_preference", answers.get("dividend_preference")),
            "sector_preference": self._get_label("sector_preference", answers.get("sector_preference")),
        }
        return summary

    def _get_label(self, question_id: str, option_id: Optional[str]) -> str:
        if not option_id:
            return ""
        q = next((q for q in self.questions if q["question_id"] == question_id), None)
        if not q:
            return ""
        opt = next((o for o in q["options"] if o["id"] == option_id), None)
        return opt["label"] if opt else ""

    # def _check_domain_restriction(self, message: str) -> Optional[str]:
    #     """ê¸ˆìœµ/íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì°¨ë‹¨ ì‘ë‹µì„ ë°˜í™˜."""
    #     msg = (message or "").lower()
    #     finance_keywords = [

    #     # íˆ¬ì/ì£¼ì‹ ì¼ë°˜
    #     "ì£¼ì‹", "ì¢…ëª©", "íˆ¬ì", "ì „ëµ", "ì‹œì¥", "ë°±í…ŒìŠ¤íŠ¸", "í¬íŠ¸í´ë¦¬ì˜¤", "í€€íŠ¸",
    #     "ì¬ë¬´", "ì¬ë¬´ì œí‘œ", "ë¦¬ìŠ¤í¬", "ìˆ˜ìµë¥ ", "ë§¤ìˆ˜", "ë§¤ë„",

    #     # ê¸°ë³¸ íŒ©í„°/ì§€í‘œ
    #     "per", "pbr", "psr", "roe", "roa", "eps", "ebitda", "ev", "fcf",

    #     # ê¸°ìˆ ì  ì§€í‘œ
    #     "rsi", "macd", "sma", "ema", "ë³¼ë¦°ì €", "stochastic",

    #     # ë°±í…ŒìŠ¤íŠ¸ ì£¼ìš” ì§€í‘œ
    #     "cagr", "ì—°í™˜ì‚°", "ì—°í‰ê· ",
    #     "mdd", "max drawdown", "ë‚™í­",
    #     "ìƒ¤í”„", "sharpe",
    #     "ì†Œí‹°ë…¸", "sortino",
    #     "ìŠ¹ë¥ ", "win rate",
    #     "ì†ìµë¹„", "profit factor", "pf",
    #     "ë³€ë™ì„±", "volatility",
    #     "ëˆ„ì  ìˆ˜ìµë¥ ", "cumulative",
    #     "ì—°ë„ë³„", "ì›”ë³„",
    #     "ë“œë¡œìš°ë‹¤ìš´", "drawdown",
    #     "íšŒë³µê¸°ê°„", "duration",

    #     # ë‰´ìŠ¤/í…Œë§ˆ
    #     "ë‰´ìŠ¤", "í…Œë§ˆ", "ì„¹í„°", "ê°ì„±",
    #     ]


    #     # ì „ëµ ì¸ë¬¼ ì´ë¦„(ë¬¸ì„œ ë‚´ ë“±ì¥) í—ˆìš©
    #     strategy_people = [
    #         "ì›Œë Œë²„í•", "ì›ŒëŸ° ë²„í•", "ë²„í•", "ì›Œë Œ ë²„í•",
    #         "ë²¤ì €ë¯¼ ê·¸ë ˆì´ì—„", "ê·¸ë ˆì´ì—„",
    #         "í”¼í„° ë¦°ì¹˜", "ë¦°ì¹˜",
    #         "ë ˆì´ ë‹¬ë¦¬ì˜¤", "ë‹¬ë¦¬ì˜¤",
    #         "ì°°ë¦¬ ë©ê±°", "ë©ê±°",
    #         "ì¡°ì—˜ ê·¸ë¦°ë¸”ë¼íŠ¸", "ê·¸ë¦°ë¸”ë¼íŠ¸",
    #     ]

    #     if any(k.lower() in msg for k in finance_keywords + strategy_people):
    #         return None
    #     # ìì—°ì–´ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ì— ê±¸ë¦¬ë©´ ê¸ˆìœµ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼
    #     if self._detect_nl_categories(message):
    #         return None

    #     return (
    #         "ì´ ì„œë¹„ìŠ¤ëŠ” íˆ¬ìÂ·ê¸ˆìœµ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤. "
    #         "ì£¼ì‹, ì‹œì¥, ì „ëµ, ë‰´ìŠ¤ ë“± ê¸ˆìœµ ì£¼ì œë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
    #     )

    async def _classify_intent(self, message: str) -> str:
        """ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜. DSL ìƒì„±ê³¼ ì„¤ëª… ëª¨ë“œë¥¼ ëª…í™•íˆ êµ¬ë¶„í•©ë‹ˆë‹¤."""
        message_lower = message.strip().lower()
        message_norm = self._normalize_text(message)

        # ê²€ì¦ ê´€ë ¨ í‚¤ì›Œë“œ (ìµœìš°ì„  - DSL ìƒì„±ë³´ë‹¤ ë¨¼ì € ì²´í¬)
        verification_keywords = ['ë§ì•„', 'ë§ë‚˜', 'ë§ëŠ”ì§€', 'ë§ë‹ˆ', 'í™•ì¸', 'ê²€ì¦', 'ì²´í¬', 'ì´ê²Œ ë§', 'ë§ëŠ” ê±°']
        
        # í˜„ì¬ ì„¤ì •ëœ ì¡°ê±´ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê²€ì¦ ìš”ì²­
        has_current_conditions = '[í˜„ì¬ ì„¤ì •ëœ ì¡°ê±´]' in message

        # DSL ìƒì„± í‚¤ì›Œë“œ (ì¡°ê±´, ì „ëµ ìƒì„± ê´€ë ¨)
        dsl_keywords = ['ë§Œë“¤', 'ìƒì„±', 'per', 'pbr', 'roe', 'roa',
                        'rsi', 'macd', 'sma', 'ema', 'ì´í•˜', 'ì´ìƒ', 'ì´ˆê³¼', 'ë¯¸ë§Œ']

        # Explain í‚¤ì›Œë“œ (ì„¤ëª…, í•´ì„ ê´€ë ¨)
        explain_keywords = ['ì„¤ëª…', 'explain', 'ë­', 'ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'how', 'ì™œ', 'why',
                           'ì•Œë ¤ì¤˜', 'ê°€ë¥´ì³', 'cagr', 'mdd', 'ìƒ¤í”„', 'sharpe', 'ì˜ë¯¸']

        # ì „ëµ ì¶”ì²œ í‚¤ì›Œë“œ
        recommend_keywords = ['ì „ëµ ì¶”ì²œ', 'recommend', 'ì¶”ì²œ']
        backtest_keywords = [
            'ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •', 'ì „ëµìœ¼ë¡œ ì§„í–‰', 'ì „ëµìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸', 'ì´ ì „ëµìœ¼ë¡œ', 'ìë™ ì„¤ì •','ë°±í…ŒìŠ¤íŒ…', 'ë°±í…ŒìŠ¤íŠ¸',"í…ŒìŠ¤íŠ¸",
            'ë°±í…ŒìŠ¤íŠ¸ ì§„í–‰', 'ì„¤ì •í•´ì¤˜', 'ì „ëµ ì‹¤í–‰', 'ì „ëµ ì„¤ì •', 'ì‹¤í–‰í•´ì¤˜','í•˜ê³ ì‹¶ì–´','ì¡°ê±´ ì„¤ì •','ì¡°ê±´ ë§Œë“¤ì–´ì¤˜'
        ]

        # ë‹¨ì¼ ì§€í‘œ/íŒ©í„° + ì§ˆë¬¸í˜•(ë­/ì˜ë¯¸/ì„¤ëª…)ì€ explainìœ¼ë¡œ ìš°ì„  ì²˜ë¦¬
        factor_keywords = ['per', 'pbr', 'roe', 'roa', 'rsi', 'sma', 'ema', 'macd', 'mdd', 'ìƒ¤í”„', 'sharpe']
        if any(f in message_lower for f in factor_keywords) and any(k in message_lower for k in explain_keywords):
            return 'explain'

        # ì „ëµëª…ì´ í¬í•¨ë˜ì–´ ìˆê³  'ë°±í…ŒìŠ¤íŠ¸' í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°•ì œ backtest_configuration
        if "ë°±í…ŒìŠ¤íŠ¸" in message_lower and self.strategy_backtest_templates:
            for sid, meta in self.strategy_backtest_templates.items():
                name_norm = self._normalize_text(meta["strategy_name"])
                if sid in message_norm or name_norm in message_norm:
                    return 'backtest_configuration'

        # ìš°ì„ ìˆœìœ„: ê²€ì¦ > ë°±í…ŒìŠ¤íŠ¸ ì„¤ì • > ì „ëµ ì¶”ì²œ > DSL ìƒì„± > Explain > General
        if has_current_conditions or any(word in message_lower for word in verification_keywords):
            return 'explain'  # ê²€ì¦ì€ explain ëª¨ë“œë¡œ ì²˜ë¦¬ (LLMì´ ìì—°ì–´ë¡œ ë‹µë³€)
        elif any(word in message_lower for word in backtest_keywords):
            return 'backtest_configuration'
        elif any(word in message_lower for word in recommend_keywords):
            return 'recommend'
        elif any(word in message_lower for word in dsl_keywords):
            return 'dsl_generation'
        elif any(word in message_lower for word in explain_keywords):
            return 'explain'
        else:
            return 'general'

    def _handle_backtest_configuration(self, message: str, session_id: str) -> dict:
        """ì „ëµ ì„ íƒ í›„ ë°±í…ŒìŠ¤íŠ¸ ì„¤ì • UI Languageë¥¼ ë°˜í™˜í•˜ê³  ê¸°ë³¸ DSLì„ ì €ì¥."""
        state = self.session_state.get(session_id, {})
        message_lower = message.lower().strip()

        # ì‚¬ìš©ìê°€ ì´ì „ì— ì„ íƒì§€ë¥¼ ë°›ì•˜ê³  "1", "2", "3" ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•œ ê²½ìš°
        if "pending_custom_condition" in state:
            custom_info = state["pending_custom_condition"]
            user_choice = None

            # ì‚¬ìš©ì ì„ íƒ í™•ì¸
            if message_lower in ["1", "â‘ ", "ì»¤ìŠ¤í…€", "ì»¤ìŠ¤í…€ë§Œ", "ì»¤ìŠ¤í…€ ì¡°ê±´ë§Œ"]:
                user_choice = 1
            elif message_lower in ["2", "â‘¡", "ì „ëµ", "ì „ëµë§Œ", "ì „ëµë§Œ ì ìš©"]:
                user_choice = 2
            elif message_lower in ["3", "â‘¢", "ë‘˜ë‹¤", "ëª¨ë‘", "ì „ëµ + ì»¤ìŠ¤í…€", "ì»¤ìŠ¤í…€ + ì „ëµ"]:
                user_choice = 3

            if user_choice:
                # ì„ íƒì— ë”°ë¼ ë°±í…ŒìŠ¤íŠ¸ ì¡°ê±´ ì„¤ì •
                days = custom_info["days"]
                pct_value = custom_info["pct_value"]

                # ì»¤ìŠ¤í…€ ë§¤ìˆ˜ ì¡°ê±´ ìƒì„±
                custom_buy_condition = {
                    "factor": f"RET_{days}D",
                    "operator": ">",
                    "value": pct_value,
                    "params": []
                }

                if user_choice == 1:
                    # ì»¤ìŠ¤í…€ ì¡°ê±´ë§Œ ì ìš©
                    state["backtest_conditions"] = {
                        "buy": [custom_buy_condition],
                        "sell": []
                    }
                    state["selected_strategy"] = "custom"
                    strategy_name = "ì»¤ìŠ¤í…€ ì¡°ê±´"
                elif user_choice == 2:
                    # ê¸°ë³¸ ì „ëµë§Œ ì ìš© (ì›Œë Œë²„í•)
                    matched_id = "warren_buffett"
                    tpl = self.strategy_backtest_templates[matched_id]
                    state["backtest_conditions"] = {
                        "buy": self._filter_valid_conditions(tpl["buy_conditions"]),
                        "sell": self._filter_valid_conditions(tpl["sell_conditions"]),
                    }
                    state["selected_strategy"] = matched_id
                    strategy_name = tpl["strategy_name"]
                else:  # user_choice == 3
                    # ì „ëµ + ì»¤ìŠ¤í…€ ì¡°ê±´ ëª¨ë‘ ì ìš©
                    matched_id = "warren_buffett"
                    tpl = self.strategy_backtest_templates[matched_id]
                    buy_conditions = self._filter_valid_conditions(tpl["buy_conditions"])
                    buy_conditions.append(custom_buy_condition)
                    state["backtest_conditions"] = {
                        "buy": buy_conditions,
                        "sell": self._filter_valid_conditions(tpl["sell_conditions"]),
                    }
                    state["selected_strategy"] = f"{matched_id}_custom"
                    strategy_name = f"{tpl['strategy_name']} + ì»¤ìŠ¤í…€ ì¡°ê±´"

                # pending_custom_condition ì œê±°
                del state["pending_custom_condition"]

                # UI Language ìƒì„± ë° ë°˜í™˜
                return self._generate_backtest_ui(state, strategy_name, session_id)

        # ì»¤ìŠ¤í…€ ìˆ˜ìµë¥  ì¡°ê±´(ì˜ˆ: 5ì¼ ì „ ëŒ€ë¹„ 5% ìƒìŠ¹) ì—¬ë¶€ë¥¼ ë¨¼ì € ê°ì§€í•´ ì „ëµ ë®ì–´ì“°ê¸° ë°©ì§€
        import re
        ret_pattern = re.search(r"(\d+)\s*ì¼.*?(\d+)\s*%.*?(ìƒìŠ¹|ì¦ê°€|ì˜¬ë¼)", message)
        has_custom_return = bool(ret_pattern)

        # ì „ëµ ì‹ë³„ (ê°„ë‹¨íˆ ì´ë¦„ ë§¤ì¹­)
        message_norm = self._normalize_text(message)
        matched_id = None
        for sid, meta in self.strategy_backtest_templates.items():
            alias_tokens = self.strategy_alias_map.get(sid, [])
            if not alias_tokens:
                alias_tokens = [self._normalize_text(meta["strategy_name"])]
            if any(token and token in message_norm for token in alias_tokens):
                matched_id = sid
                break

        # ì „ëµ ë¯¸ì§€ì • + ì»¤ìŠ¤í…€ ì¡°ê±´ì´ ê°ì§€ë˜ë©´ ìë™ ì „ëµ ì„¤ì •ì„ í”¼í•˜ê³  ëª…í™•í™” ì§ˆë¬¸
        if not matched_id and has_custom_return:
            days, pct, _ = ret_pattern.groups()
            pct_value = float(pct) / 100 if pct else None
            example = f"RET_{days}D > {pct_value:.2f}" if pct_value is not None else ""

            # ì„¸ì…˜ì— ì»¤ìŠ¤í…€ ì¡°ê±´ ì •ë³´ ì €ì¥ (ì‚¬ìš©ì ì„ íƒì„ ìœ„í•´)
            state = self.session_state.setdefault(session_id, {})
            state["pending_custom_condition"] = {
                "days": days,
                "pct": pct,
                "pct_value": pct_value,
                "example": example
            }

            return {
                "answer": (
                    f"{days}ì¼ ì „ ëŒ€ë¹„ {pct}% ìƒìŠ¹ ì¡°ê±´ì´ ê°ì§€ëì–´ìš”.\n"
                    "ë°±í…ŒìŠ¤íŠ¸ë¥¼ ì–´ë–»ê²Œ ì§„í–‰í• ê¹Œìš”?\n"
                    "â‘  ì»¤ìŠ¤í…€ ì¡°ê±´ë§Œ ì ìš© (ì˜ˆ: "
                    f"{example})\n"
                    "â‘¡ íŠ¹ì • ì „ëµë§Œ ì ìš© (ì „ëµëª… ì•Œë ¤ì£¼ì„¸ìš”)\n"
                    "â‘¢ ì „ëµ + ì»¤ìŠ¤í…€ ì¡°ê±´ ëª¨ë‘ ì ìš©\n"
                    "ì›í•˜ëŠ” ë²ˆí˜¸ë‚˜ ì „ëµëª…ì„ ì•Œë ¤ì£¼ì„¸ìš”."
                ),
                "intent": "clarify_backtest",
                "session_id": session_id,
            }

        # ê¸°ë³¸ê°’: ì›Œë Œë²„í•
        if not matched_id:
            matched_id = "warren_buffett"
        tpl = self.strategy_backtest_templates[matched_id]

        # ì„¸ì…˜ ìƒíƒœì— DSL ì €ì¥ (ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œ ì‚¬ìš©)
        state = self.session_state.setdefault(session_id, {})
        state["backtest_conditions"] = {
            "buy": self._filter_valid_conditions(tpl["buy_conditions"]),
            "sell": self._filter_valid_conditions(tpl["sell_conditions"]),
        }
        state["selected_strategy"] = matched_id

        answer = (
            f"{tpl['strategy_name']}ìœ¼ë¡œ ì§„í–‰í• ê²Œìš”.\n"
            "í•´ë‹¹ ì „ëµì˜ ë§¤ìˆ˜ ê¸°ì¤€ê³¼ ë§¤ë„ ê¸°ì¤€ì„ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n\n"
            "ì„¤ì •ì´ ì™„ë£Œë˜ë©´ ë°”ë¡œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”."
        )

        ui_language = {
            "type": "backtest_configuration",
            "strategy": {
                "strategy_id": matched_id,
                "strategy_name": tpl["strategy_name"],
            },
            "configuration_fields": [
                {
                    "field_id": "initial_capital",
                    "label": "ì´ˆê¸° íˆ¬ì ê¸ˆì•¡",
                    "type": "number",
                    "unit": "ì›",
                    "default_value": 10000000,
                    "min_value": 1000000,
                    "max_value": 1000000000,
                    "step": 1000000,
                    "required": True,
                },
                {
                    "field_id": "start_date",
                    "label": "ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼",
                    "type": "date",
                    "default_value": "2021-01-01",
                    "min_value": "2005-01-01",
                    "max_value": "2025-01-01",
                    "required": True,
                },
                {
                    "field_id": "end_date",
                    "label": "ë°±í…ŒìŠ¤íŠ¸ ì¢…ë£Œì¼",
                    "type": "date",
                    "default_value": "2024-12-31",
                    "min_value": "2005-01-01",
                    "max_value": "2025-01-01",
                    "required": True,
                },
                {
                    "field_id": "rebalance_frequency",
                    "label": "ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°",
                    "type": "select",
                    "default_value": "MONTHLY",
                    "options": [
                        {"value": "DAILY", "label": "ë§¤ì¼"},
                        {"value": "WEEKLY", "label": "ë§¤ì£¼"},
                        {"value": "MONTHLY", "label": "ë§¤ì›”"},
                    ],
                    "required": True,
                },
            ],
        }

        return {
            "answer": answer,
            "intent": "backtest_configuration",
            "ui_language": ui_language,
            "backtest_conditions": state["backtest_conditions"],
        }

    async def _retrieve_context(self, message: str, intent: str) -> str:
        """Retrieve relevant context from RAG and Backend."""
        context_parts = []

        # 1. Backend íŒ©í„° ì •ë³´ ì¡°íšŒ
        if self.factor_sync and intent in ["recommend", "build"]:
            try:
                # ë©”ì‹œì§€ì—ì„œ íŒ©í„° í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
                message_lower = message.lower()

                # ì „ëµ í‚¤ì›Œë“œ ë§¤í•‘
                strategy_keywords = {
                    "ê°€ì¹˜": "value", "ì €í‰ê°€": "value", "per": "value", "pbr": "value",
                    "ì„±ì¥": "growth", "ë§¤ì¶œ": "growth", "ì´ìµ": "growth",
                    "ìš°ëŸ‰": "quality", "roe": "quality", "roa": "quality",
                    "ëª¨ë©˜í…€": "momentum", "ì¶”ì„¸": "momentum", "ìˆ˜ìµë¥ ": "momentum",
                    "ë°°ë‹¹": "dividend"
                }

                detected_strategy = None
                for keyword, strategy in strategy_keywords.items():
                    if keyword in message_lower:
                        detected_strategy = strategy
                        break

                if detected_strategy:
                    # ì „ëµë³„ íŒ©í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    strategy_info = await self.factor_sync.build_strategy_recommendation(detected_strategy)
                    context_parts.append(f"ì „ëµ: {strategy_info['description']}")
                    context_parts.append(f"ì£¼ìš” íŒ©í„°: {', '.join(strategy_info['primary_factors'])}")
                else:
                    # ì „ì²´ íŒ©í„° ëª©ë¡ ìš”ì•½
                    all_factors = await self.factor_sync.get_all_factors()
                    if all_factors:
                        factor_summary = f"ì‚¬ìš© ê°€ëŠ¥í•œ íŒ©í„° ìˆ˜: {len(all_factors)}"
                        context_parts.append(factor_summary)
            except Exception as e:
                print(f"Backend context retrieval error: {e}")

        # 2. RAG ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰ (í•­ìƒ í™œì„±í™” - MDD, CAGR ë“± ìš©ì–´ ì§ˆë¬¸ ì²˜ë¦¬)
        if self.rag_retriever:
            try:
                rag_context = await self.rag_retriever.get_context(
                    message,
                    top_k=self.config.get("rag", {}).get("top_k", 3)
                )
                if rag_context:
                    context_parts.append(f"\n[ì§€ì‹ ë² ì´ìŠ¤]\n{rag_context}")
                    print(f"DEBUG: RAG context retrieved ({len(rag_context)} chars)")
            except Exception as e:
                print(f"RAG retrieval error: {e}")

        # 3. ë‰´ìŠ¤ ê²€ìƒ‰ì€ Claudeì˜ Tool Useë¡œ ì²˜ë¦¬ (ìë™ ê²€ìƒ‰ ë¹„í™œì„±í™”)
        # Claudeê°€ í•„ìš”ì‹œ search_stock_news ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤

        return "\n".join(context_parts) if context_parts else ""

    def _ensure_news_retriever(self) -> None:
        """ë‰´ìŠ¤ ë¦¬íŠ¸ë¦¬ë²„ê°€ ì—†ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ë¡œ ì¬ì´ˆê¸°í™”."""
        if self.news_retriever is not None:
            return
        backend_url = os.getenv("BACKEND_URL") or os.getenv("STOCK_LAB_API_URL")
        if not backend_url:
            backend_url = "http://backend:8000/api/v1"
        if NewsRetriever:
            try:
                self.news_retriever = NewsRetriever(backend_url)
                print(f"[NewsRetriever] Lazy initialized with {backend_url}")
            except Exception as exc:
                print(f"[NewsRetriever] Lazy init failed: {exc}")
                self.news_retriever = None

    def _format_news_unavailable(self, message: str) -> str:
        """ë‰´ìŠ¤ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì‹œ í…œí”Œë¦¿í˜• ì•ˆë‚´ ë©”ì‹œì§€ ìƒì„±."""
        title = (message.strip() or "ì‹œì¥ ë™í–¥")[:30]
        return (
            f"## {title}\n"
            "- **ë°ì´í„° ì—†ìŒ**: í˜„ì¬ ë‰´ìŠ¤/í…Œë§ˆ ê°ì„± ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            "- **ëŒ€ì•ˆ**: ë‰´ìŠ¤ ì„œë¹„ìŠ¤ ë³µêµ¬ í›„ ë‹¤ì‹œ ìš”ì²­í•´ì£¼ì„¸ìš”.\n"
            "- **ì°¸ê³ **: ë‹¤ë¥¸ íˆ¬ì/ì „ëµ ì§ˆë¬¸ì€ ë°”ë¡œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
            "ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: ì„œë¹„ìŠ¤ ë³µêµ¬ ì‹œ ë‹¤ì‹œ í…Œë§ˆ ë™í–¥ì„ ìš”ì²­í•´ì£¼ì„¸ìš”"
        )

    def _generate_backtest_ui(self, state: dict, strategy_name: str) -> dict:
        """ë°±í…ŒìŠ¤íŠ¸ UI Language ìƒì„± í—¬í¼ í•¨ìˆ˜"""
        answer = (
            f"{strategy_name}ìœ¼ë¡œ ì§„í–‰í• ê²Œìš”.\n"
            "í•´ë‹¹ ì „ëµì˜ ë§¤ìˆ˜ ê¸°ì¤€ê³¼ ë§¤ë„ ê¸°ì¤€ì„ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n\n"
            "ì„¤ì •ì´ ì™„ë£Œë˜ë©´ ë°”ë¡œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”."
        )

        ui_language = {
            "type": "backtest_configuration",
            "strategy": {
                "strategy_id": state.get("selected_strategy", "custom"),
                "strategy_name": strategy_name,
            },
            "configuration_fields": [
                {
                    "field_id": "initial_capital",
                    "label": "ì´ˆê¸° íˆ¬ì ê¸ˆì•¡",
                    "type": "number",
                    "unit": "ì›",
                    "default_value": 10000000,
                    "min_value": 1000000,
                    "max_value": 1000000000,
                    "step": 1000000,
                    "required": True,
                },
                {
                    "field_id": "start_date",
                    "label": "ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼",
                    "type": "date",
                    "default_value": "2021-01-01",
                    "min_value": "2005-01-01",
                    "max_value": "2025-01-01",
                    "required": True,
                },
                {
                    "field_id": "end_date",
                    "label": "ë°±í…ŒìŠ¤íŠ¸ ì¢…ë£Œì¼",
                    "type": "date",
                    "default_value": "2024-12-31",
                    "min_value": "2005-01-01",
                    "max_value": "2025-01-01",
                    "required": True,
                },
                {
                    "field_id": "rebalance_frequency",
                    "label": "ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°",
                    "type": "select",
                    "default_value": "MONTHLY",
                    "options": [
                        {"value": "DAILY", "label": "ë§¤ì¼"},
                        {"value": "WEEKLY", "label": "ë§¤ì£¼"},
                        {"value": "MONTHLY", "label": "ë§¤ì›”"},
                    ],
                    "required": True,
                },
            ],
        }

        return {
            "answer": answer,
            "intent": "backtest_configuration",
            "ui_language": ui_language,
            "backtest_conditions": state["backtest_conditions"],
        }

    def _filter_valid_conditions(self, conditions: List[dict]) -> List[dict]:
        """factor/operator ì—†ëŠ” ì¡°ê±´ì€ ë°±í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì œê±°."""
        valid = [
            c for c in conditions
            if c.get("factor") and c.get("operator") is not None
        ]
        dropped = len(conditions) - len(valid)
        if dropped:
            print(f"DSL ì¡°ê±´ í•„í„°ë§: {dropped}ê°œ í•„ìˆ˜ í•„ë“œ ëˆ„ë½ìœ¼ë¡œ ì œê±°")
        return valid

    def _normalize_text(self, text: str) -> str:
        """ì†Œë¬¸ì + ê³µë°± ì œê±°ë¡œ ê°„ë‹¨íˆ ì •ê·œí™”."""
        return re.sub(r"\s+", "", text.lower())

    def _normalize_cache_text(self, text: str) -> str:
        """ìºì‹œ í‚¤ìš© ì •ê·œí™” (ì†Œë¬¸ì + ê³µë°± ì¶•ì†Œ)."""
        return re.sub(r"\s+", " ", (text or "").strip().lower())

    def _fallback_parse_simple_conditions(self, message: str) -> List[dict]:
        """LLM DSL íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ê·œì¹™ìœ¼ë¡œ ì¡°ê±´ ì¶”ì¶œ."""
        text = self._normalize_condition_separators(message.lower())
        # ë¬¸ì¥ ë¶„í• : ì¤„ë°”ê¿ˆ, ì‰¼í‘œ, ê·¸ë¦¬ê³ /ë°
        chunks = re.split(r"[\n,]+|\s+ê·¸ë¦¬ê³ \s+|\s+ë°\s+", text)
        conditions: List[dict] = []

        op_map = {
            "ì´í•˜": "<=",
            "ë¯¸ë§Œ": "<",
            "ì´ìƒ": ">=",
            "ì´ˆê³¼": ">",
        }

        for chunk in chunks:
            chunk = chunk.strip()
            if not chunk:
                continue

            # íŒ¨í„´: [íŒ©í„°] [ìˆ«ì][%ì˜µì…˜] [ë¹„êµì–´]
            match = re.search(r"([a-zA-Zê°€-í£_]+)\s*([\d\.]+)\s*(%|í¼ì„¼íŠ¸)?\s*(ì´ìƒ|ì´ˆê³¼|ì´í•˜|ë¯¸ë§Œ)", chunk)
            if not match:
                # íŒ¨í„´ì´ ë°˜ëŒ€ ìˆœì„œì¸ ê²½ìš° (ì˜ˆ: 30 ì´í•˜ë©´ RSI)
                match_alt = re.search(r"([\d\.]+)\s*(%|í¼ì„¼íŠ¸)?\s*(ì´ìƒ|ì´ˆê³¼|ì´í•˜|ë¯¸ë§Œ)\s*([a-zA-Zê°€-í£_]+)", chunk)
                if not match_alt:
                    continue
                factor_raw = match_alt.group(4)
                value_raw = match_alt.group(1)
                pct = match_alt.group(2) or ""
                op_kr = match_alt.group(3)
            else:
                factor_raw = match.group(1)
                value_raw = match.group(2)
                pct = match.group(3) or ""
                op_kr = match.group(4)

            operator = op_map.get(op_kr)
            if not operator:
                continue

            try:
                value = float(value_raw)
            except ValueError:
                continue

            conditions.append({
                "factor": factor_raw.upper(),
                "params": [],
                "operator": operator,
                "right_factor": None,
                "right_params": [],
                "value": value,
            })

        if conditions:
            print(f"[DSL Fallback] {len(conditions)}ê°œ ì¡°ê±´ì„ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ íŒŒì‹±")
        return conditions

    def _merge_text_extracted_conditions(self, conditions: List[dict], message: str) -> List[dict]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ê°ì§€í•œ ì¡°ê±´ì„ ì¶”ê°€ë¡œ ë³‘í•©."""
        existing_factors = {str(c.get("factor") or "").upper() for c in conditions}
        extracted = self._extract_conditions_from_text(message)

        for cond in extracted:
            factor = str(cond.get("factor") or "").upper()
            if not factor:
                continue
            if factor in existing_factors:
                continue
            conditions.append(cond)
            existing_factors.add(factor)

        return conditions

    def _extract_conditions_from_text(self, message: str) -> List[dict]:
        """ìì—°ì–´ì—ì„œ ì§ì ‘ ì¡°ê±´ì„ ì¶”ì¶œ (LLM ëˆ„ë½ ëŒ€ë¹„)."""
        text = self._normalize_condition_separators((message or "").lower())
        chunks = re.split(r"[\n,]+|\s+ê·¸ë¦¬ê³ \s+|\s+ë°\s+", text)
        conditions: List[dict] = []

        op_map = {
            "ì´í•˜": "<=",
            "ë¯¸ë§Œ": "<",
            "ì´ìƒ": ">=",
            "ì´ˆê³¼": ">",
        }

        for chunk in chunks:
            chunk = chunk.strip()
            if not chunk:
                continue

            m = re.search(r"([a-zA-Zê°€-í£_]+)\s*([\d\.]+)\s*(%|í¼ì„¼íŠ¸)?\s*(ì´ìƒ|ì´ˆê³¼|ì´í•˜|ë¯¸ë§Œ)", chunk)
            if not m:
                m = re.search(r"([\d\.]+)\s*(%|í¼ì„¼íŠ¸)?\s*(ì´ìƒ|ì´ˆê³¼|ì´í•˜|ë¯¸ë§Œ)\s*([a-zA-Zê°€-í£_]+)", chunk)
                if not m:
                    continue
                factor = m.group(4)
                value_raw = m.group(1)
                op_kr = m.group(3)
            else:
                factor = m.group(1)
                value_raw = m.group(2)
                op_kr = m.group(4)

            operator = op_map.get(op_kr)
            if not operator:
                continue

            try:
                value = float(value_raw)
            except ValueError:
                continue

            conditions.append({
                "factor": factor.upper(),
                "params": [],
                "operator": operator,
                "right_factor": None,
                "right_params": [],
                "value": value,
            })

        return conditions

    def _normalize_condition_separators(self, text: str) -> str:
        """ì¡°ê±´ ì—°ê²°ì–´ë¥¼ í‘œì¤€í™” (ì´í•˜ì´ê³ , ì´ìƒì´ê³  ë“±)."""
        if not text:
            return text
        # "ì´í•˜ì´ê³ " â†’ "ì´í•˜ ê·¸ë¦¬ê³ ", ë“± ë¹„êµì–´ ë’¤ì— ë¶™ì€ 'ì´ê³ 'ë¥¼ ë¶„ë¦¬
        text = re.sub(r"(ì´í•˜|ì´ìƒ|ë¯¸ë§Œ|ì´ˆê³¼)\s*ì´ê³ ", r"\1 ê·¸ë¦¬ê³ ", text)
        # ìˆ«ì/í¼ì„¼íŠ¸ ë’¤ì— ë°”ë¡œ 'ì´ê³ 'ê°€ ë¶™ì€ ê²½ìš° ë¶„ë¦¬
        text = re.sub(r"(\d+(?:\.\d+)?\s*%?)\s*ì´ê³ ", r"\1 ê·¸ë¦¬ê³ ", text)
        return text

    def _make_dsl_cache_key(self, message: str) -> Optional[str]:
        """DSL ìºì‹œ í‚¤ ìƒì„±."""
        if not message:
            return None
        norm = self._normalize_cache_text(message)
        digest = hashlib.sha256(norm.encode("utf-8")).hexdigest()
        return f"dsl:{self.DSL_CACHE_VERSION}:{digest}"

    def _get_cache(self, key: Optional[str]) -> Optional[dict]:
        if not key or not self.cache_client:
            return None
        try:
            raw = self.cache_client.get(key)
            if raw:
                return json.loads(raw)
        except Exception as e:
            self.logger.warning(f"Redis ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

    def _set_cache(self, key: Optional[str], value: dict, ttl: int = 600):
        if not key or not self.cache_client:
            return
        try:
            self.cache_client.setex(key, ttl, json.dumps(value, ensure_ascii=False))
        except Exception as e:
            self.logger.warning(f"Redis ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _postprocess_condition_values(self, conditions: List[dict], message: str) -> List[dict]:
        """ìì—°ì–´ ìˆ«ì/ìŠ¤ì¼€ì¼ì„ ë¬¸ë§¥ ê¸°ë°˜ìœ¼ë¡œ ë³´ì •."""
        if not conditions:
            return conditions

        message_lower = (message or "").lower()
        raw_scale_factors = {"per", "pbr", "psr", "peg"}

        def _value_from_text(factor_token: str) -> Optional[float]:
            pattern = rf"{re.escape(factor_token)}\s*([0-9]+(?:\.[0-9]+)?)"
            m = re.search(pattern, message_lower)
            if m:
                try:
                    return float(m.group(1))
                except ValueError:
                    return None
            return None

        for cond in conditions:
            factor = str(cond.get("factor") or "").lower()
            value = cond.get("value")
            if not factor or value is None:
                continue

            text_value = _value_from_text(factor)
            if text_value is not None:
                cond["value"] = text_value
                continue

            if factor in raw_scale_factors and isinstance(value, (int, float)) and 0 < abs(value) < 1:
                cond["value"] = round(value * 100, 4)

        return conditions

    def _build_strategy_aliases(self, strategy_id: str, name: Optional[str], aliases: Optional[List[str]]) -> List[str]:
        """ì „ëµ ì´ë¦„/ë³„ì¹­ì„ ì •ê·œí™”ëœ í† í° ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„±."""
        tokens: set[str] = set()

        def _add(token: Optional[str]):
            if not token or not isinstance(token, str):
                return
            normalized = self._normalize_text(token)
            if normalized:
                tokens.add(normalized)

        _add(strategy_id)
        _add(name)
        if name:
            stripped = re.sub(r"ì „ëµ$", "", name).strip()
            _add(stripped)

        if aliases and isinstance(aliases, list):
            for alias in aliases:
                if not isinstance(alias, str):
                    continue
                _add(alias)
                stripped_alias = re.sub(r"ì „ëµ$", "", alias).strip()
                _add(stripped_alias)

        return list(tokens)

    def _load_dsl_system_prompt(self) -> Optional[str]:
        """Load DSL-specific portion from system.txt if present."""
        prompt_path = Path("/app/prompts/system.txt")
        if not prompt_path.exists():
            prompt_path = Path(__file__).parent.parent.parent / "prompts" / "system.txt"

        try:
            content = prompt_path.read_text(encoding="utf-8")
        except Exception as e:
            print(f"DSL ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

        marker = "ğŸ“Œ DSL ìƒì„± í…œí”Œë¦¿"
        if marker not in content:
            return content

        # Grab DSL ì„¹ì…˜ë¶€í„° ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ ì „ê¹Œì§€ ì¶”ì¶œ
        import re
        match = re.search(r"ğŸ“Œ DSL ìƒì„± í…œí”Œë¦¿.*?(?=\n=+\nğŸ“Œ |\Z)", content, flags=re.DOTALL)
        if match:
            return match.group(0).strip()

        return content

    def _load_system_prompt_content(self, filename: str, fallback_text: str) -> str:
        """Load custom system prompt, fallback to legacy system.txt or default text."""
        prompt_path = Path("/app/prompts") / filename
        if not prompt_path.exists():
            prompt_path = Path(__file__).parent.parent.parent / "prompts" / filename

        if prompt_path.exists():
            try:
                return prompt_path.read_text(encoding="utf-8")
            except Exception as exc:
                print(f"ê²½ê³ : {filename} ë¡œë“œ ì‹¤íŒ¨ ({exc}), ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")

        legacy_path = Path("/app/prompts/system.txt")
        if not legacy_path.exists():
            legacy_path = Path(__file__).parent.parent.parent / "prompts" / "system.txt"
        if legacy_path.exists():
            try:
                return legacy_path.read_text(encoding="utf-8")
            except Exception:
                pass

        return fallback_text

    def _get_agent_executor(self, client_type: str):
        """Return AgentExecutor for client_type (fallback to assistant)."""
        if client_type == "ai_helper":
            normalized = "ai_helper"
        elif client_type == "home_widget":
            normalized = "home_widget"
        else:
            normalized = "assistant"
        executor = self.agent_executors.get(normalized)
        if executor:
            return executor
        return self.agent_executors.get("assistant")

    async def _generate_response_langchain(
        self,
        message: str,
        intent: str,
        context: str,
        session_id: Optional[str],
        client_type: str = "assistant"
    ) -> dict:
        """Generate response using LangChain Agent."""
        executor = self._get_agent_executor(client_type)
        if not executor:
            error_msg = (
                "LangChain Agent not initialized. "
                f"Provider: {self.provider}, "
                f"LLM Client: {self.llm_client is not None}, "
                f"ChatBedrock available: {ChatBedrock is not None}"
            )
            print(error_msg)
            return {
                "answer": error_msg,
                "intent": intent
            }

        # Get or create conversation memory for the session
        memory_key = f"{client_type}:{session_id}"
        if memory_key not in self.conversation_history:
            self.conversation_history[memory_key] = ChatMessageHistory()
        memory = self.conversation_history[memory_key]

        try:
            # Use asyncio.to_thread to run the synchronous invoke method in a separate thread
            # Pass inputs in a structured dictionary, not a single message list
            chat_history = getattr(memory, "messages", []) if memory else []

            # Prepare invoke input
            # Note: agent_scratchpad is required for both tool-calling and ReAct agents
            # Pass as empty string for initial invocation
            print(f"DEBUG INVOKE: Message='{message}', Context length={len(context)} chars")
            if context:
                print(f"DEBUG CONTEXT: {context[:500]}...")
            invoke_input = {
                "input": message,
                "context": context,
                "chat_history": chat_history,
                "agent_scratchpad": ""  # Required by both agent types
            }


            # LangChain 0.2+ì—ì„œëŠ” ainvoke ì§€ì›, ì—†ìœ¼ë©´ sync invokeë¥¼ ì“°ë˜ ìŠ¤ë ˆë“œë¡œ ì˜¤í”„ë¡œë“œ
            if hasattr(executor, "ainvoke"):
                response = await executor.ainvoke(invoke_input)
            else:
                response = await asyncio.to_thread(
                    executor.invoke,
                    invoke_input
                )

            answer = response.get("output", "No response generated.")
            if isinstance(answer, list):
                formatted_parts = []
                for element in answer:
                    if isinstance(element, str):
                        formatted_parts.append(element)
                    elif isinstance(element, dict):
                        text = element.get("text") or element.get("message") or element.get("output")
                        if isinstance(text, str):
                            formatted_parts.append(text)
                        else:
                            formatted_parts.append(str(text))
                    else:
                        formatted_parts.append(str(element))
                answer = "\n".join(formatted_parts)


            answer = self._clean_tool_calls_from_response(answer)

            # Manually save conversation history to the session's memory
            if memory:
                memory.add_user_message(message)
                memory.add_ai_message(answer)

            # Extract backtest conditions from intermediate steps if build_backtest_conditions was called
            backtest_conditions = None
            intermediate_steps = response.get("intermediate_steps", [])
            print(f"DEBUG: intermediate_steps count: {len(intermediate_steps)}")

            for i, step in enumerate(intermediate_steps):
                print(f"DEBUG: Step {i}: type={type(step)}, len={len(step) if hasattr(step, '__len__') else 'N/A'}")
                if len(step) >= 2:
                    action, result = step[0], step[1]
                    print(f"DEBUG: Action type: {type(action)}, has tool attr: {hasattr(action, 'tool')}")
                    if hasattr(action, 'tool'):
                        print(f"DEBUG: Action.tool = '{action.tool}'")
                    print(f"DEBUG: Result type: {type(result)}, content: {result}")

                    # Check if this was a build_backtest_conditions tool call
                    if hasattr(action, 'tool') and action.tool == 'build_backtest_conditions':
                        print(f"DEBUG: Found build_backtest_conditions tool!")
                        if isinstance(result, dict) and result.get("success"):
                            backtest_conditions = result.get("conditions", [])
                            print(f"DEBUG: Extracted conditions: {backtest_conditions}")
                            break
                        else:
                            print(f"DEBUG: Result not successful or not dict: {result}")

            result_dict = {
                "answer": answer,
                "intent": intent,
                "context": context
            }

            if backtest_conditions:
                result_dict["backtest_conditions"] = backtest_conditions

            return result_dict
        except Exception as e:
            error_str = str(e)
            self._log_agent_error(
                error=e,
                intent=intent,
                client_type=client_type,
                message=message,
                context=context
            )

            # Throttling ì—ëŸ¬ì¸ ê²½ìš° ì¹œì ˆí•œ ë©”ì‹œì§€
            if "ThrottlingException" in error_str or "Too many requests" in error_str:
                user_message = "ğŸš¦ ìš”ì²­ì´ ë§ì•„ ì¼ì‹œì ìœ¼ë¡œ ì‘ë‹µì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì ì‹œ í›„(2-3ë¶„) ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            else:
                user_message = "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\në‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

            return {
                "answer": user_message,
                "intent": intent
            }

    def _log_agent_error(
        self,
        error: Exception,
        intent: str,
        client_type: str,
        message: str,
        context: str
    ) -> None:
        """ì—ì´ì „íŠ¸ ì‹¤íŒ¨ ì‹œ ë””ë²„ê¹… ì •ë³´ë¥¼ êµ¬ì¡°í™”í•´ ë¡œê¹…."""
        bedrock_info = None
        if self.provider == "bedrock":
            bedrock_info = {
                "region": self.llm_region,
                "model_id": self.llm_model_id,
                "inference_profile_id": self.llm_inference_profile_id,
                "target_id": self.llm_target_id,
                "env_model_id": os.getenv("BEDROCK_MODEL_ID"),
                "env_inference_profile_id": os.getenv("BEDROCK_INFERENCE_PROFILE_ID") or os.getenv("BEDROCK_INFERENCE_PROFILE_ARN"),
            }

        error_log = {
            "event": "langchain_agent_error",
            "intent": intent,
            "client_type": client_type,
            "provider": self.provider,
            "error": str(error),
            "traceback": traceback.format_exc(),
            "context_chars": len(context or ""),
            "message_chars": len(message or ""),
            "bedrock": bedrock_info,
            "message_ko": "LangChain ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        }
        try:
            # í•œêµ­ì–´ ìš”ì•½ + JSON ìƒì„¸ ëª¨ë‘ ì¶œë ¥
            print(
                "ERROR: LangChain ì—ì´ì „íŠ¸ ì˜¤ë¥˜ ë°œìƒ | "
                f"ì˜ë„={intent}, í´ë¼ì´ì–¸íŠ¸={client_type}, ì œê³µì={self.provider}, "
                f"BedrockëŒ€ìƒ={self.llm_target_id or self.llm_model_id}"
            )
            print(f"ERROR: {json.dumps(error_log, ensure_ascii=False)}")
        except Exception:
            print(f"ERROR: langchain_agent_error (fallback print) {error_log}")

    def _clean_tool_calls_from_response(self, response: str) -> str:
        """LangChainì˜ ë‚´ë¶€ ë„êµ¬ í˜¸ì¶œ í˜•ì‹(<function_calls>, <invoke> ë“±)ì„ ì œê±°í•©ë‹ˆë‹¤."""
        # <function_calls> ë¸”ë¡ ì œê±°
        response = re.sub(
            r'<function_calls>.*?</function_calls>',
            '',
            response,
            flags=re.DOTALL
        )

        # <invoke> ë¸”ë¡ ì œê±°
        response = re.sub(
            r'<invoke>.*?</invoke>',
            '',
            response,
            flags=re.DOTALL
        )

        # ì—°ì†ëœ ë¹ˆ ì¤„ ì œê±°
        response = re.sub(r'\n\n+', '\n\n', response)

        return response.strip()

    async def _handle_dsl_mode(self, message: str, _session_id: str) -> dict:
        """DSL ìƒì„± ëª¨ë“œ ì²˜ë¦¬.

        - RAG ê²€ìƒ‰ ê¸ˆì§€ (context ì—†ìŒ)
        - DSL ì „ìš© system prompt ì‚¬ìš©
        - build_backtest_conditions ë„êµ¬ í˜¸ì¶œí•˜ì—¬ JSON ìƒì„±
        - backtest_conditions í•„ë“œë¡œ ë¶„ë¦¬í•˜ì—¬ ë°˜í™˜
        """
        cache_key = self._make_dsl_cache_key(message)
        cached = self._get_cache(cache_key)
        if cached:
            return cached

        # system.txtì—ì„œ DSL í…œí”Œë¦¿ ì˜ì—­ì„ ì¶”ì¶œí•´ dsl_generatorì— ì ìš©
        dsl_system_prompt = self._load_dsl_system_prompt()

        # LLM í´ë¼ì´ì–¸íŠ¸ í™•ì¸
        if not self.llm_client:
            return {
                "answer": "LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "intent": "dsl_generation"
        }

        try:
            # build_backtest_conditions ë„êµ¬ ì§ì ‘ í˜¸ì¶œ
            from schemas import dsl_generator
            original_prompt = getattr(dsl_generator, "CLAUDE_SYSTEM_PROMPT", "")

            if dsl_system_prompt:
                try:
                    # system.txt DSL í…œí”Œë¦¿ + ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ ì•ˆë‚´ë¥¼ í•¨ê»˜ ì „ë‹¬í•´ í¬ë§· ìœ ì§€
                    combined_prompt = (
                        f"{dsl_system_prompt}\n\n{original_prompt}" if original_prompt else dsl_system_prompt
                    )
                    dsl_generator.CLAUDE_SYSTEM_PROMPT = combined_prompt
                    print(f"DSL ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš© ì™„ë£Œ ({len(combined_prompt)} ì)")
                except Exception as e:
                    print(f"DSL ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš© ì‹¤íŒ¨: {e}")

            parse_strategy_text = dsl_generator.parse_strategy_text

            # ìì—°ì–´ â†’ DSL ë³€í™˜
            result = parse_strategy_text(message)

            # Condition ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (Pydantic v1 í˜¸í™˜)
            conditions = [condition.dict() for condition in result.conditions]
            # í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ì¡°ê±´ì€ ì œê±°
            conditions = self._filter_valid_conditions(conditions)

            # ê¸°ë³¸ DSL íŒŒì‹±ì´ ì‹¤íŒ¨í•˜ë©´ ë‹¨ìˆœ ê·œì¹™ ê¸°ë°˜ íŒŒì„œë¡œ ì¬ì‹œë„
            if not conditions:
                conditions = self._fallback_parse_simple_conditions(message)

            # í…ìŠ¤íŠ¸ì—ì„œ ì¶”ê°€ë¡œ ê°ì§€ë˜ëŠ” ì¡°ê±´ì„ ë³‘í•© (LLM ëˆ„ë½ ë°©ì§€)
            conditions = self._merge_text_extracted_conditions(conditions, message)

            # ìì—°ì–´ ìˆ«ìì™€ ìŠ¤ì¼€ì¼ì´ ì–´ê¸‹ë‚˜ë©´ ë¬¸ì¥ ê¸°ë°˜ìœ¼ë¡œ ë³´ì •
            conditions = self._postprocess_condition_values(conditions, message)

            if not conditions:
                return {
                    "answer": "ì¡°ê±´ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì¡°ê±´ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆì‹œ:\n- PER 10 ì´í•˜\n- ROE 15% ì´ìƒ\n- RSI 30 ì´í•˜ë©´ ë§¤ìˆ˜",
                    "intent": "dsl_generation",
                    "backtest_conditions": {"buy": [], "sell": []}
                }

            # ë©”ì‹œì§€ë¥¼ ë¶„ì„í•´ì„œ ë§¤ìˆ˜/ë§¤ë„ ì¡°ê±´ ë¶„ë¦¬
            import re

            buy_keywords = ["ë§¤ìˆ˜", "ìƒìŠ¹", "ì˜¤ë¥´ë©´", "ì˜¤ë¥¼", "ìƒí–¥", "ëŒíŒŒ"]
            sell_keywords = ["ë§¤ë„", "í•˜ë½", "ë‚´ë¦¬ë©´", "ë–¨ì–´ì§€ë©´", "ë‚´ë¦¼", "ì†ì ˆ", "í•˜í–¥"]

            message_lower = message.lower()

            def _percent_variants(value: float) -> List[str]:
                """value(ì†Œìˆ˜)ë¥¼ ì‚¬ëŒì´ ì…ë ¥í•œ í¼ì„¼íŠ¸ í‘œí˜„ìœ¼ë¡œ ë³€í™˜."""
                pct = abs(value * 100)
                variants = set()
                formatted = (
                    str(int(pct))
                    if float(pct).is_integer()
                    else f"{pct:.2f}".rstrip("0").rstrip(".")
                )
                variants.add(f"{formatted}%")
                variants.add(f"{formatted} %")
                variants.add(f"{formatted}í¼ì„¼íŠ¸")
                variants.add(f"{formatted} í¼ì„¼íŠ¸")
                variants.add(f"{pct}%")
                variants.add(f"{pct} %")
                variants.add(str(value))
                return [v.lower() for v in variants if v]

            def _find_indicator_position(cond: Dict[str, Any]) -> int:
                """ì¡°ê±´ê³¼ ì—°ê´€ëœ í…ìŠ¤íŠ¸ì˜ ëŒ€ëµì ì¸ ìœ„ì¹˜ íƒìƒ‰."""
                factor = cond.get("factor", "")
                params = cond.get("params", []) or []
                value = cond.get("value")
                search_tokens: List[str] = []

                if isinstance(factor, str) and factor:
                    search_tokens.append(factor.lower())
                    match = re.match(r"(?:RET|PRICE_CHANGE)_(\d+)D", factor.upper())
                    if match:
                        days_token = match.group(1)
                        search_tokens.extend([
                            f"{days_token}ì¼",
                            f"{days_token} ì¼",
                            f"{days_token}ì¼ê°„",
                            f"{days_token} ì¼ê°„",
                        ])

                for param in params:
                    token = str(param).strip()
                    if token:
                        search_tokens.append(token.lower())

                if isinstance(value, (int, float)):
                    search_tokens.extend(_percent_variants(value))

                for token in search_tokens:
                    pos = message_lower.find(token)
                    if pos != -1:
                        return pos
                return -1

            def _find_keyword_after(start: int, keywords: List[str]) -> int:
                best = -1
                for kw in keywords:
                    idx = message_lower.find(kw, max(start, 0))
                    if idx != -1 and (best == -1 or idx < best):
                        best = idx
                return best

            def _find_keyword_before(start: int, keywords: List[str]) -> int:
                best = -1
                end = start if start != -1 else len(message_lower)
                for kw in keywords:
                    idx = message_lower.rfind(kw, 0, end)
                    if idx != -1 and idx > best:
                        best = idx
                return best

            def _classify_condition(cond: Dict[str, Any]) -> str:
                indicator_pos = _find_indicator_position(cond)
                start_idx = indicator_pos if indicator_pos != -1 else 0

                buy_pos = _find_keyword_after(start_idx, buy_keywords)
                sell_pos = _find_keyword_after(start_idx, sell_keywords)
                if buy_pos != -1 or sell_pos != -1:
                    if sell_pos == -1 or (buy_pos != -1 and buy_pos <= sell_pos):
                        return "buy"
                    return "sell"

                # í‚¤ì›Œë“œë¥¼ ë’¤ì—ì„œ ì°¾ëŠ” ê²½ìš° (ì˜ˆ: "ë§¤ë„ ì¡°ê±´: ...")
                buy_prev = _find_keyword_before(start_idx, buy_keywords)
                sell_prev = _find_keyword_before(start_idx, sell_keywords)
                if buy_prev == -1 and sell_prev == -1:
                    return "buy"
                if sell_prev == -1 or (buy_prev != -1 and buy_prev >= sell_prev):
                    return "buy"
                return "sell"

            buy_conditions: List[Dict[str, Any]] = []
            sell_conditions: List[Dict[str, Any]] = []
            for cond in conditions:
                target_bucket = _classify_condition(cond)
                if target_bucket == "sell":
                    sell_conditions.append(cond)
                else:
                    buy_conditions.append(cond)

            # ì¡°ê±´ í¬ë§·íŒ… (ìš”ì•½í˜•)
            def _fmt_value(val: Any) -> str:
                if isinstance(val, (int, float)):
                    if float(val).is_integer():
                        return str(int(val))
                    return str(round(val, 6)).rstrip("0").rstrip(".")
                return str(val)

            def _fmt(cond: Dict[str, Any]) -> str:
                factor = cond['factor']
                operator = cond['operator']
                value = cond.get('value')
                params = cond.get('params', [])
                if params:
                    factor_str = f"{factor}({', '.join(map(str, params))})"
                else:
                    factor_str = factor
                return f"{factor_str} {operator} {_fmt_value(value)}" if value is not None else factor_str

            buy_summary = ", ".join([_fmt(c) for c in buy_conditions]) if buy_conditions else ""
            sell_summary = ", ".join([_fmt(c) for c in sell_conditions]) if sell_conditions else ""

            summary_lines = []
            if buy_summary:
                summary_lines.append(f"ë§¤ìˆ˜: {buy_summary}")
            if sell_summary:
                summary_lines.append(f"ë§¤ë„: {sell_summary}")
            summary_text = "\n".join(summary_lines) if summary_lines else "ì¡°ê±´ì„ ë²„íŠ¼ìœ¼ë¡œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

            answer_text = (
                "## ìš”ì•½\n"
                f"{summary_text}\n\n"
                "### ë‹¤ìŒ ë‹¨ê³„\n"
                "- ë§¤ìˆ˜/ë§¤ë„ ì¡°ê±´ ë²„íŠ¼ìœ¼ë¡œ ë°”ë¡œ ì ìš©\n"
                "- ìˆ˜ì¹˜ ì¡°ì •ì´ í•„ìš”í•˜ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”"
            )

            response_payload = {
                "answer": answer_text,
                "intent": "dsl_generation",
                "backtest_conditions": {
                    "buy": buy_conditions,
                    "sell": sell_conditions
                }
            }

            self._set_cache(cache_key, response_payload)
            return response_payload
        except Exception as e:
            print(f"DSL ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {
                "answer": f"DSL ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "intent": "dsl_generation",
                "backtest_conditions": []
            }

    async def _handle_explain_mode(self, message: str, session_id: str, client_type: str) -> dict:
        """ì„¤ëª… ëª¨ë“œ ì²˜ë¦¬.

        - RAG ê²€ìƒ‰ í™œì„±í™” (ì§€ì‹ ë² ì´ìŠ¤ í™œìš©)
        - Explain ì „ìš© system prompt ì‚¬ìš©
        - Markdown í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë‹µë³€ ë°˜í™˜
        """
        # Explain ëª¨ë“œì—ì„œëŠ” RAG ê²€ìƒ‰ í™œì„±í™”
        context = await self._retrieve_context(message, 'explain')

        # Explain ì „ìš© í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        prompt_path = Path("/app/prompts/explain.txt")
        if not prompt_path.exists():
            prompt_path = Path(__file__).parent.parent.parent / "prompts" / "explain.txt"

        if prompt_path.exists():
            explain_system_prompt = prompt_path.read_text(encoding='utf-8')
        else:
            explain_system_prompt = """
ë‹¹ì‹ ì€ í€€íŠ¸ íˆ¬ì ì „ë¬¸ AI ì–´ë“œë°”ì´ì €ì…ë‹ˆë‹¤.

ë‹µë³€ ê·œì¹™:
- í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€
- Markdown í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë‹µë³€ ì œê³µ
- ì„¹ì…˜ ì œëª© ì‚¬ìš© (## ğŸ“Œ ì œëª©)
- ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…
- ì „ë¬¸ì„± ìœ ì§€
"""

        # LangChain Agentë¡œ ì‘ë‹µ ìƒì„± (RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
        return await self._generate_response_langchain(
            message, 'explain', context, session_id, client_type
        )

    def _check_investment_advisory_policy(self, message: str, session_id: Optional[str] = None) -> Optional[str]:
        """íˆ¬ì ì¡°ì–¸ ì •ì±… ìœ„ë°˜ í™•ì¸.

        Returns:
            ì •ì±… ìœ„ë°˜ ë©”ì‹œì§€ (ìœ„ë°˜ ì‹œ), None (ì •ì±… ì¤€ìˆ˜ ì‹œ)
        """
        # í•œê¸€ì€ ëŒ€ì†Œë¬¸ìê°€ ì—†ìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        message_check = message.strip()

        # íŒ¨í„´ ë§¤ì¹­
        violations_found = []
        for violation_type, patterns in self.forbidden_patterns.items():
            for pattern in patterns:
                if __import__('re').search(pattern, message_check):
                    violations_found.append(violation_type)
                    break

        if violations_found:
            violation_type = violations_found[0]
            self._log_policy_block(violation_type, session_id or "", message)
            return self._get_policy_violation_response(violation_type)

        return None

    def _get_policy_violation_response(self, violation_type: str) -> str:
        """ì •ì±… ìœ„ë°˜ì— ë”°ë¥¸ ì‘ë‹µ ë©”ì‹œì§€ ë°˜í™˜."""
        base_response = (
            "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” íŠ¹ì • ì¢…ëª©ì— ëŒ€í•œ íˆ¬ì ì¡°ì–¸ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "ëŒ€ì‹  ë„ì›€ë“œë¦´ ìˆ˜ ìˆëŠ” ê²ƒ:\n"
            "- ì¢…ëª© ë¶„ì„ ë°©ë²• ì„¤ëª…\n"
            "- ì¬ë¬´ì œí‘œ ì½ëŠ” ë²•\n"
            "- íˆ¬ì ì§€í‘œ ê³„ì‚° ë°©ë²•\n"
            "-  ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì›ì¹™\n\n"
            "íˆ¬ì ê²°ì •ì€ ë°˜ë“œì‹œ ë³¸ì¸ì˜ íŒë‹¨ìœ¼ë¡œ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        )

        if violation_type == "ì¢…ëª©_ì¶”ì²œ":
            return (
                "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” íŠ¹ì • ì¢…ëª©ì„ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                "ëŒ€ì‹  ë‹¤ìŒì„ ë„ì›€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n"
                "- íŒ©í„° ë¶„ì„ ë°©ë²•\n"
                "- ì¢…ëª© í‰ê°€ ë°©ë²•\n"
                "- íˆ¬ì ì „ëµ ì„¤ëª…\n\n"
                "íˆ¬ì ê²°ì •ì€ ì¶©ë¶„í•œ ë¦¬ì„œì¹˜ í›„ ë³¸ì¸ì˜ íŒë‹¨ìœ¼ë¡œ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
            )
        elif violation_type == "ë§¤ë§¤_ì‹œì ":
            return (
                "ì£„ì†¡í•©ë‹ˆë‹¤. ë§¤ë§¤ íƒ€ì´ë°ì— ëŒ€í•œ ì¡°ì–¸ì€ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                "ëŒ€ì‹  ë‹¤ìŒì„ ë„ì›€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n"
                "- ê¸°ìˆ ì  ë¶„ì„ ë°©ë²•\n"
                "- ì°¨íŠ¸ ì½ëŠ” ë²•\n"
                "- ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ëµ\n\n"
                "ë§¤ë§¤ íƒ€ì´ë°ì€ ë³¸ì¸ì˜ íˆ¬ì ê³„íšê³¼ íŒë‹¨ìœ¼ë¡œ ê²°ì •í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
            )
        elif violation_type == "ìˆ˜ìµë¥ _ë³´ì¥":
            return (
                "ì£„ì†¡í•©ë‹ˆë‹¤. ìˆ˜ìµì„ ë³´ì¥í•´ë“œë¦´ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤.\n\n"
                "íˆ¬ìì—ëŠ” í•­ìƒ ì†ì‹¤ì˜ ìœ„í—˜ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ëŒ€ì‹  ë‹¤ìŒì„ ë„ì›€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n"
                "- ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ë²•\n"
                "- í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚° ì „ëµ\n"
                "- ì—­ì‚¬ì  ìˆ˜ìµë¥  ë°ì´í„° ë¶„ì„\n\n"
                "ì•ˆì •ì ì¸ ì¥ê¸° íˆ¬ì ê³„íšì„ ì„¸ìš°ì‹œê¸° ë°”ëë‹ˆë‹¤."
            )
        elif violation_type == "ê°œì¸í™”_ì¡°ì–¸":
            return (
                "ì£„ì†¡í•©ë‹ˆë‹¤. ê°œì¸ì˜ ìƒí™©ì— ë§ì¶˜ íˆ¬ì ì¡°ì–¸ì€ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                "ëŒ€ì‹  ë‹¤ìŒì„ ë„ì›€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n"
                "- ì¼ë°˜ì ì¸ íˆ¬ì ì „ëµ ì„¤ëª…\n"
                "- ìì‚°ë°°ë¶„ ì›ì¹™\n"
                "- íˆ¬ì ëª©í‘œ ì„¤ì • ë°©ë²•\n\n"
                "ë³¸ì¸ì˜ ìƒí™©ê³¼ ëª©í‘œì— ë§ëŠ” íˆ¬ì ê³„íšì„ ì„¸ìš°ì‹œê¸° ë°”ëë‹ˆë‹¤."
            )
        elif violation_type == "ë¹„ì†ì–´":
            return (
                "ì„œë¹„ìŠ¤ í’ˆì§ˆ ìœ ì§€ë¥¼ ìœ„í•´ ë¹„ì†ì–´Â·ìš•ì„¤ì€ ì°¨ë‹¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
                "ê¶ê¸ˆí•œ ì ì„ ì •ì¤‘í•œ í‘œí˜„ìœ¼ë¡œ ë§ì”€í•´ì£¼ì‹œë©´ ë¹ ë¥´ê²Œ ë„ì™€ë“œë¦´ê²Œìš”."
            )
        elif violation_type == "ë„ë°•":
            return (
                "ë„ë°•Â·ë² íŒ… ê´€ë ¨ ë‚´ìš©ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. íˆ¬ìÂ·ê¸ˆìœµ ê´€ë ¨ ì§ˆë¬¸ë§Œ ë°›ì•„ìš”.\n"
                "ì£¼ì‹ ì‹œì¥, ì „ëµ, ì§€í‘œ ë“±ì— ëŒ€í•´ ë¬¼ì–´ë´ì£¼ì„¸ìš”."
            )

        return base_response

    def _log_policy_block(self, violation_type: str, session_id: str, message: str):
        """ê°ì‚¬ ì¶”ì ìš© ì •ì±… ì°¨ë‹¨ ë¡œê·¸."""
        try:
            snippet = (message or "").strip()
            if len(snippet) > 200:
                snippet = snippet[:200] + "...(truncated)"
            log_payload = {
                "event": "policy_block",
                "violation_type": violation_type,
                "session_id": session_id,
                "message": snippet,
            }
            if self.logger:
                self.logger.info(json.dumps(log_payload, ensure_ascii=False))
            else:
                print(json.dumps(log_payload, ensure_ascii=False))
        except Exception as e:
            print(f"Failed to log policy block: {e}")
